{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import mlflow\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"vehicles_train\", {}, \"Vehicle detection.v9i.coco/train/_annotations.coco.json\", \"Vehicle detection.v9i.coco/train\")\n",
    "register_coco_instances(\"v\", {}, \"Vehicle detection.v9i.coco/test/_annotations.coco.json\", \"Vehicle detection.v9i.coco/test\")\n",
    "register_coco_instances(\"vehicles_val\", {}, \"Vehicle detection.v9i.coco/valid/_annotations.coco.json\", \"Vehicle detection.v9i.coco/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg, CfgNode\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.MLFLOW = CfgNode()\n",
    "cfg.MLFLOW.EXPERIMENT_NAME = \"Vehicle Object Detection\"\n",
    "cfg.MLFLOW.RUN_DESCRIPTION = \"training with 6000 iterations, 20k images\"\n",
    "cfg.MLFLOW.RUN_NAME = \"#4 training\" # TODO: Исправить на автосмену\n",
    "cfg.MLFLOW.TRACKING_URI = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import HookBase\n",
    "import mlflow\n",
    "\n",
    "class MLflowHook(HookBase):\n",
    "    \"\"\"\n",
    "    A custom hook class that logs artifacts, metrics, and parameters to MLflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg.clone()\n",
    "\n",
    "    def before_train(self):\n",
    "        with torch.no_grad():\n",
    "            mlflow.set_tracking_uri(self.cfg.MLFLOW.TRACKING_URI)\n",
    "            mlflow.set_experiment(self.cfg.MLFLOW.EXPERIMENT_NAME)\n",
    "            mlflow.start_run(run_name=self.cfg.MLFLOW.RUN_NAME)\n",
    "            mlflow.set_tag(\"mlflow.note.content\",\n",
    "                           self.cfg.MLFLOW.RUN_DESCRIPTION)\n",
    "            for k, v in self.cfg.items():\n",
    "                mlflow.log_param(k, v)\n",
    "\n",
    "    def after_step(self):\n",
    "        with torch.no_grad():\n",
    "            latest_metrics = self.trainer.storage.latest()\n",
    "            for k, v in latest_metrics.items():\n",
    "                mlflow.log_metric(key=k, value=v[0], step=v[1])\n",
    "\n",
    "    def after_train(self):\n",
    "        with torch.no_grad():\n",
    "            with open(os.path.join(self.cfg.OUTPUT_DIR, \"model-config.yaml\"), \"w\") as f:\n",
    "                f.write(self.cfg.dump())\n",
    "            mlflow.log_artifacts(self.cfg.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    A custom trainer class that evaluates the model on the validation set every `_C.TEST.EVAL_PERIOD` iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(cfg.OUTPUT_DIR_VALIDATION_SET_EVALUATION,\n",
    "                        exist_ok=True)\n",
    "        \n",
    "        return COCOEvaluator(dataset_name, distributed=False, output_dir=cfg.OUTPUT_DIR_VALIDATION_SET_EVALUATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/06 14:02:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:02:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:02:46 d2.data.datasets.coco]: \u001b[0mLoaded 16020 images in COCO format from Vehicle detection.v9i.coco/train/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:02:46 d2.data.build]: \u001b[0mRemoved 6106 images with no usable annotations. 9914 images left.\n",
      "\u001b[32m[03/06 14:02:47 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "|    cars    | 0            |     bike      | 1654         |    bus     | 590          |\n",
      "|    car     | 6356         | constructio.. | 1002         | emergency  | 2256         |\n",
      "| motorbike  | 1004         | personal mo.. | 714          | quad bike  | 680          |\n",
      "|   truck    | 734          |               |              |            |              |\n",
      "|   total    | 14990        |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/06 14:02:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/06 14:02:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/06 14:02:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:02:47 d2.data.common]: \u001b[0mSerializing 9914 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:02:47 d2.data.common]: \u001b[0mSerialized dataset takes 3.04 MiB\n",
      "\u001b[32m[03/06 14:02:47 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=20\n",
      "\u001b[32m[03/06 14:02:47 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (10, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (36, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (36,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/06 14:02:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forssh/workspace/.venv/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/06 14:03:14 d2.utils.events]: \u001b[0m eta: 1:57:06  iter: 19  total_loss: 2.637  loss_cls: 2.071  loss_box_reg: 0.09347  loss_rpn_cls: 0.3656  loss_rpn_loc: 0.09955    time: 1.1751  last_time: 1.1845  data_time: 0.0771  last_data_time: 0.0477   lr: 4.9953e-06  max_mem: 13695M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 14:03:15.269369: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-06 14:03:15.313267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-06 14:03:15.313306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-06 14:03:15.315059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-06 14:03:15.323921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/06 14:03:42 d2.utils.events]: \u001b[0m eta: 1:57:13  iter: 39  total_loss: 2.471  loss_cls: 1.913  loss_box_reg: 0.1048  loss_rpn_cls: 0.3396  loss_rpn_loc: 0.08848    time: 1.1858  last_time: 1.1790  data_time: 0.0614  last_data_time: 0.0683   lr: 9.9902e-06  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:04:08 d2.utils.events]: \u001b[0m eta: 1:56:28  iter: 59  total_loss: 2.008  loss_cls: 1.567  loss_box_reg: 0.09429  loss_rpn_cls: 0.2486  loss_rpn_loc: 0.08162    time: 1.1849  last_time: 1.1341  data_time: 0.0579  last_data_time: 0.0432   lr: 1.4985e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:04:35 d2.utils.events]: \u001b[0m eta: 1:56:47  iter: 79  total_loss: 1.719  loss_cls: 1.076  loss_box_reg: 0.1065  loss_rpn_cls: 0.3406  loss_rpn_loc: 0.08687    time: 1.1912  last_time: 1.2317  data_time: 0.0572  last_data_time: 0.0799   lr: 1.998e-05  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:05:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:05:00 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:05:01 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "|    cars    | 0            |     bike      | 353          |    bus     | 119          |\n",
      "|    car     | 2402         | constructio.. | 120          | emergency  | 355          |\n",
      "| motorbike  | 240          | personal mo.. | 103          | quad bike  | 148          |\n",
      "|   truck    | 268          |               |              |            |              |\n",
      "|   total    | 4108         |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/06 14:05:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:05:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:05:01 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:05:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:05:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:05:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0007 s/iter. Inference: 0.0435 s/iter. Eval: 0.0004 s/iter. Total: 0.0446 s/iter. ETA=0:02:15\n",
      "\u001b[32m[03/06 14:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 128/3060. Dataloading: 0.0012 s/iter. Inference: 0.0412 s/iter. Eval: 0.0004 s/iter. Total: 0.0429 s/iter. ETA=0:02:05\n",
      "\u001b[32m[03/06 14:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 245/3060. Dataloading: 0.0012 s/iter. Inference: 0.0412 s/iter. Eval: 0.0004 s/iter. Total: 0.0429 s/iter. ETA=0:02:00\n",
      "\u001b[32m[03/06 14:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 356/3060. Dataloading: 0.0013 s/iter. Inference: 0.0419 s/iter. Eval: 0.0004 s/iter. Total: 0.0436 s/iter. ETA=0:01:57\n",
      "\u001b[32m[03/06 14:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 472/3060. Dataloading: 0.0013 s/iter. Inference: 0.0417 s/iter. Eval: 0.0004 s/iter. Total: 0.0435 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/06 14:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 569/3060. Dataloading: 0.0013 s/iter. Inference: 0.0417 s/iter. Eval: 0.0019 s/iter. Total: 0.0449 s/iter. ETA=0:01:51\n",
      "\u001b[32m[03/06 14:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 677/3060. Dataloading: 0.0013 s/iter. Inference: 0.0422 s/iter. Eval: 0.0016 s/iter. Total: 0.0452 s/iter. ETA=0:01:47\n",
      "\u001b[32m[03/06 14:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 792/3060. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0015 s/iter. Total: 0.0450 s/iter. ETA=0:01:42\n",
      "\u001b[32m[03/06 14:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 905/3060. Dataloading: 0.0013 s/iter. Inference: 0.0422 s/iter. Eval: 0.0013 s/iter. Total: 0.0449 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 14:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 1013/3060. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0012 s/iter. Total: 0.0451 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 14:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 1126/3060. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0011 s/iter. Total: 0.0451 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 14:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 1240/3060. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0011 s/iter. Total: 0.0450 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 14:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 1349/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0010 s/iter. Total: 0.0451 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 14:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 1457/3060. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0012 s/iter. Total: 0.0452 s/iter. ETA=0:01:12\n",
      "\u001b[32m[03/06 14:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 1570/3060. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0011 s/iter. Total: 0.0451 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/06 14:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 1681/3060. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0011 s/iter. Total: 0.0451 s/iter. ETA=0:01:02\n",
      "\u001b[32m[03/06 14:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 1791/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0010 s/iter. Total: 0.0452 s/iter. ETA=0:00:57\n",
      "\u001b[32m[03/06 14:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 1906/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0010 s/iter. Total: 0.0451 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/06 14:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 2019/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0010 s/iter. Total: 0.0451 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/06 14:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 2128/3060. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0009 s/iter. Total: 0.0451 s/iter. ETA=0:00:42\n",
      "\u001b[32m[03/06 14:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 2243/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0009 s/iter. Total: 0.0450 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/06 14:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 2357/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0009 s/iter. Total: 0.0450 s/iter. ETA=0:00:31\n",
      "\u001b[32m[03/06 14:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 2465/3060. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0009 s/iter. Total: 0.0450 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/06 14:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 2586/3060. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0008 s/iter. Total: 0.0449 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/06 14:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 2708/3060. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0010 s/iter. Total: 0.0447 s/iter. ETA=0:00:15\n",
      "\u001b[32m[03/06 14:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 2843/3060. Dataloading: 0.0013 s/iter. Inference: 0.0420 s/iter. Eval: 0.0009 s/iter. Total: 0.0443 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 14:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 2976/3060. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0009 s/iter. Total: 0.0441 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 14:07:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.656159 (0.044077 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:07:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:07 (0.041785 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:07:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:07:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:07:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.65s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=5.94s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      "\u001b[32m[03/06 14:07:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.204 | 0.759  | 0.021  | 0.000 | 0.153 | 0.284 |\n",
      "\u001b[32m[03/06 14:07:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.004 | bus        | 0.004 |\n",
      "| car        | 1.418 | construction equipment | 0.042 | emergency  | 0.097 |\n",
      "| motorbike  | 0.001 | personal mobility      | 0.002 | quad bike  | 0.265 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:07:38 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:07:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:07:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:07:38 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2037,0.7586,0.0212,0.0002,0.1531,0.2836\n",
      "\u001b[32m[03/06 14:07:38 d2.utils.events]: \u001b[0m eta: 1:56:33  iter: 99  total_loss: 1.053  loss_cls: 0.6008  loss_box_reg: 0.1072  loss_rpn_cls: 0.2524  loss_rpn_loc: 0.08459    time: 1.1929  last_time: 1.1984  data_time: 0.0499  last_data_time: 0.0432   lr: 2.4975e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:08:07 d2.utils.events]: \u001b[0m eta: 1:56:50  iter: 119  total_loss: 0.6939  loss_cls: 0.3318  loss_box_reg: 0.112  loss_rpn_cls: 0.2082  loss_rpn_loc: 0.05341    time: 1.1988  last_time: 1.1788  data_time: 0.0573  last_data_time: 0.0515   lr: 2.997e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:08:36 d2.utils.events]: \u001b[0m eta: 1:56:30  iter: 139  total_loss: 0.6268  loss_cls: 0.2359  loss_box_reg: 0.1161  loss_rpn_cls: 0.1925  loss_rpn_loc: 0.05759    time: 1.2018  last_time: 1.2323  data_time: 0.0540  last_data_time: 0.0542   lr: 3.4965e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:09:06 d2.utils.events]: \u001b[0m eta: 1:56:38  iter: 159  total_loss: 0.6466  loss_cls: 0.2014  loss_box_reg: 0.1186  loss_rpn_cls: 0.1772  loss_rpn_loc: 0.0725    time: 1.2092  last_time: 1.2955  data_time: 0.0648  last_data_time: 0.0647   lr: 3.996e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:09:37 d2.utils.events]: \u001b[0m eta: 1:56:46  iter: 179  total_loss: 0.5925  loss_cls: 0.1892  loss_box_reg: 0.1211  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.0848    time: 1.2170  last_time: 1.2747  data_time: 0.0717  last_data_time: 0.0607   lr: 4.4955e-05  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:10:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:10:09 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:10:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:10:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:10:09 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:10:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:10:09 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:10:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0006 s/iter. Inference: 0.0532 s/iter. Eval: 0.0003 s/iter. Total: 0.0541 s/iter. ETA=0:02:45\n",
      "\u001b[32m[03/06 14:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 107/3060. Dataloading: 0.0017 s/iter. Inference: 0.0506 s/iter. Eval: 0.0002 s/iter. Total: 0.0526 s/iter. ETA=0:02:35\n",
      "\u001b[32m[03/06 14:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 205/3060. Dataloading: 0.0018 s/iter. Inference: 0.0497 s/iter. Eval: 0.0002 s/iter. Total: 0.0518 s/iter. ETA=0:02:28\n",
      "\u001b[32m[03/06 14:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 298/3060. Dataloading: 0.0019 s/iter. Inference: 0.0503 s/iter. Eval: 0.0002 s/iter. Total: 0.0525 s/iter. ETA=0:02:25\n",
      "\u001b[32m[03/06 14:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 395/3060. Dataloading: 0.0019 s/iter. Inference: 0.0501 s/iter. Eval: 0.0002 s/iter. Total: 0.0523 s/iter. ETA=0:02:19\n",
      "\u001b[32m[03/06 14:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 490/3060. Dataloading: 0.0019 s/iter. Inference: 0.0502 s/iter. Eval: 0.0002 s/iter. Total: 0.0524 s/iter. ETA=0:02:14\n",
      "\u001b[32m[03/06 14:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 586/3060. Dataloading: 0.0019 s/iter. Inference: 0.0502 s/iter. Eval: 0.0002 s/iter. Total: 0.0524 s/iter. ETA=0:02:09\n",
      "\u001b[32m[03/06 14:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 686/3060. Dataloading: 0.0019 s/iter. Inference: 0.0498 s/iter. Eval: 0.0002 s/iter. Total: 0.0521 s/iter. ETA=0:02:03\n",
      "\u001b[32m[03/06 14:10:50 d2.evaluation.evaluator]: \u001b[0mInference done 785/3060. Dataloading: 0.0019 s/iter. Inference: 0.0497 s/iter. Eval: 0.0002 s/iter. Total: 0.0519 s/iter. ETA=0:01:58\n",
      "\u001b[32m[03/06 14:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 878/3060. Dataloading: 0.0019 s/iter. Inference: 0.0499 s/iter. Eval: 0.0002 s/iter. Total: 0.0521 s/iter. ETA=0:01:53\n",
      "\u001b[32m[03/06 14:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 976/3060. Dataloading: 0.0019 s/iter. Inference: 0.0498 s/iter. Eval: 0.0002 s/iter. Total: 0.0521 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 14:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 1072/3060. Dataloading: 0.0019 s/iter. Inference: 0.0498 s/iter. Eval: 0.0002 s/iter. Total: 0.0521 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 14:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 1169/3060. Dataloading: 0.0019 s/iter. Inference: 0.0498 s/iter. Eval: 0.0002 s/iter. Total: 0.0520 s/iter. ETA=0:01:38\n",
      "\u001b[32m[03/06 14:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 1266/3060. Dataloading: 0.0020 s/iter. Inference: 0.0497 s/iter. Eval: 0.0002 s/iter. Total: 0.0520 s/iter. ETA=0:01:33\n",
      "\u001b[32m[03/06 14:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 1368/3060. Dataloading: 0.0020 s/iter. Inference: 0.0495 s/iter. Eval: 0.0002 s/iter. Total: 0.0518 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 14:11:25 d2.evaluation.evaluator]: \u001b[0mInference done 1473/3060. Dataloading: 0.0020 s/iter. Inference: 0.0492 s/iter. Eval: 0.0002 s/iter. Total: 0.0515 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 14:11:30 d2.evaluation.evaluator]: \u001b[0mInference done 1573/3060. Dataloading: 0.0020 s/iter. Inference: 0.0491 s/iter. Eval: 0.0002 s/iter. Total: 0.0514 s/iter. ETA=0:01:16\n",
      "\u001b[32m[03/06 14:11:35 d2.evaluation.evaluator]: \u001b[0mInference done 1676/3060. Dataloading: 0.0020 s/iter. Inference: 0.0489 s/iter. Eval: 0.0002 s/iter. Total: 0.0512 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 14:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 1778/3060. Dataloading: 0.0020 s/iter. Inference: 0.0488 s/iter. Eval: 0.0002 s/iter. Total: 0.0511 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 1882/3060. Dataloading: 0.0020 s/iter. Inference: 0.0486 s/iter. Eval: 0.0002 s/iter. Total: 0.0510 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 14:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 1987/3060. Dataloading: 0.0020 s/iter. Inference: 0.0484 s/iter. Eval: 0.0002 s/iter. Total: 0.0508 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 14:11:56 d2.evaluation.evaluator]: \u001b[0mInference done 2092/3060. Dataloading: 0.0020 s/iter. Inference: 0.0483 s/iter. Eval: 0.0002 s/iter. Total: 0.0506 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 14:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 2201/3060. Dataloading: 0.0020 s/iter. Inference: 0.0480 s/iter. Eval: 0.0002 s/iter. Total: 0.0504 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 14:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 2306/3060. Dataloading: 0.0020 s/iter. Inference: 0.0479 s/iter. Eval: 0.0002 s/iter. Total: 0.0503 s/iter. ETA=0:00:37\n",
      "\u001b[32m[03/06 14:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 2410/3060. Dataloading: 0.0020 s/iter. Inference: 0.0478 s/iter. Eval: 0.0002 s/iter. Total: 0.0502 s/iter. ETA=0:00:32\n",
      "\u001b[32m[03/06 14:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 2514/3060. Dataloading: 0.0020 s/iter. Inference: 0.0478 s/iter. Eval: 0.0002 s/iter. Total: 0.0501 s/iter. ETA=0:00:27\n",
      "\u001b[32m[03/06 14:12:21 d2.evaluation.evaluator]: \u001b[0mInference done 2617/3060. Dataloading: 0.0020 s/iter. Inference: 0.0477 s/iter. Eval: 0.0002 s/iter. Total: 0.0501 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/06 14:12:26 d2.evaluation.evaluator]: \u001b[0mInference done 2722/3060. Dataloading: 0.0020 s/iter. Inference: 0.0476 s/iter. Eval: 0.0002 s/iter. Total: 0.0500 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:12:31 d2.evaluation.evaluator]: \u001b[0mInference done 2825/3060. Dataloading: 0.0020 s/iter. Inference: 0.0476 s/iter. Eval: 0.0002 s/iter. Total: 0.0499 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/06 14:12:36 d2.evaluation.evaluator]: \u001b[0mInference done 2935/3060. Dataloading: 0.0020 s/iter. Inference: 0.0474 s/iter. Eval: 0.0002 s/iter. Total: 0.0498 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/06 14:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 3041/3060. Dataloading: 0.0020 s/iter. Inference: 0.0473 s/iter. Eval: 0.0002 s/iter. Total: 0.0497 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/06 14:12:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.839129 (0.049702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:12:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:24 (0.047298 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:12:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:12:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:12:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.55s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n",
      "\u001b[32m[03/06 14:12:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.210 | 0.598  | 0.086  | 0.000 | 0.206 | 0.263 |\n",
      "\u001b[32m[03/06 14:12:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.024 | bus        | 0.011 |\n",
      "| car        | 1.479 | construction equipment | 0.052 | emergency  | 0.076 |\n",
      "| motorbike  | 0.000 | personal mobility      | 0.000 | quad bike  | 0.252 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:12:48 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:12:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:12:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:12:48 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2103,0.5983,0.0859,0.0002,0.2062,0.2634\n",
      "\u001b[32m[03/06 14:12:48 d2.utils.events]: \u001b[0m eta: 1:57:14  iter: 199  total_loss: 0.5576  loss_cls: 0.1782  loss_box_reg: 0.1143  loss_rpn_cls: 0.1882  loss_rpn_loc: 0.07103    time: 1.2264  last_time: 1.2765  data_time: 0.0750  last_data_time: 0.0602   lr: 4.995e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:13:19 d2.utils.events]: \u001b[0m eta: 1:57:34  iter: 219  total_loss: 0.5007  loss_cls: 0.1635  loss_box_reg: 0.1058  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.08287    time: 1.2334  last_time: 1.2618  data_time: 0.0814  last_data_time: 0.0555   lr: 5.4945e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:13:50 d2.utils.events]: \u001b[0m eta: 1:58:06  iter: 239  total_loss: 0.4185  loss_cls: 0.1619  loss_box_reg: 0.107  loss_rpn_cls: 0.068  loss_rpn_loc: 0.05616    time: 1.2391  last_time: 1.3074  data_time: 0.0803  last_data_time: 0.0699   lr: 5.994e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:14:21 d2.utils.events]: \u001b[0m eta: 1:58:23  iter: 259  total_loss: 0.3999  loss_cls: 0.155  loss_box_reg: 0.1039  loss_rpn_cls: 0.09254  loss_rpn_loc: 0.0578    time: 1.2427  last_time: 1.3190  data_time: 0.0717  last_data_time: 0.0833   lr: 6.4935e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:14:51 d2.utils.events]: \u001b[0m eta: 1:58:58  iter: 279  total_loss: 0.4428  loss_cls: 0.1658  loss_box_reg: 0.1216  loss_rpn_cls: 0.07787  loss_rpn_loc: 0.06479    time: 1.2456  last_time: 1.1857  data_time: 0.0804  last_data_time: 0.0699   lr: 6.993e-05  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:15:18 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:15:18 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:15:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:15:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:15:19 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:15:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:15:19 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:15:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0371 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:01:55\n",
      "\u001b[32m[03/06 14:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 149/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/06 14:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 289/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/06 14:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 428/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/06 14:15:40 d2.evaluation.evaluator]: \u001b[0mInference done 567/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 14:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 706/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 14:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 847/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 14:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 987/3060. Dataloading: 0.0012 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/06 14:16:00 d2.evaluation.evaluator]: \u001b[0mInference done 1128/3060. Dataloading: 0.0012 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/06 14:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 1268/3060. Dataloading: 0.0012 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/06 14:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 1406/3060. Dataloading: 0.0012 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 14:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 1542/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 14:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 1680/3060. Dataloading: 0.0012 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 14:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 1818/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/06 14:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 1955/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:39\n",
      "\u001b[32m[03/06 14:16:35 d2.evaluation.evaluator]: \u001b[0mInference done 2091/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 14:16:40 d2.evaluation.evaluator]: \u001b[0mInference done 2230/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/06 14:16:45 d2.evaluation.evaluator]: \u001b[0mInference done 2370/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 14:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 2509/3060. Dataloading: 0.0012 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/06 14:16:55 d2.evaluation.evaluator]: \u001b[0mInference done 2648/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/06 14:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 2788/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 14:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 2924/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 14:17:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:50.662738 (0.036223 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:17:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:46 (0.034852 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:17:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:17:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:17:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.83s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.60s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061\n",
      "\u001b[32m[03/06 14:17:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.362 | 0.944  | 0.173  | 0.000 | 0.300 | 0.456 |\n",
      "\u001b[32m[03/06 14:17:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.038 | bus        | 0.024 |\n",
      "| car        | 2.514 | construction equipment | 0.112 | emergency  | 0.198 |\n",
      "| motorbike  | 0.000 | personal mobility      | 0.000 | quad bike  | 0.372 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:17:13 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:17:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:17:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:17:13 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3619,0.9437,0.1728,0.0005,0.3001,0.4564\n",
      "\u001b[32m[03/06 14:17:13 d2.utils.events]: \u001b[0m eta: 1:57:35  iter: 299  total_loss: 0.4327  loss_cls: 0.1507  loss_box_reg: 0.1147  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.07275    time: 1.2432  last_time: 1.2168  data_time: 0.0477  last_data_time: 0.0456   lr: 7.4925e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:17:40 d2.utils.events]: \u001b[0m eta: 1:56:35  iter: 319  total_loss: 0.4326  loss_cls: 0.1602  loss_box_reg: 0.1212  loss_rpn_cls: 0.07981  loss_rpn_loc: 0.0568    time: 1.2408  last_time: 1.2755  data_time: 0.0465  last_data_time: 0.0437   lr: 7.992e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:18:08 d2.utils.events]: \u001b[0m eta: 1:55:32  iter: 339  total_loss: 0.4135  loss_cls: 0.1453  loss_box_reg: 0.1082  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.06566    time: 1.2390  last_time: 1.2009  data_time: 0.0443  last_data_time: 0.0323   lr: 8.4915e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:18:36 d2.utils.events]: \u001b[0m eta: 1:54:48  iter: 359  total_loss: 0.4278  loss_cls: 0.1428  loss_box_reg: 0.1036  loss_rpn_cls: 0.08548  loss_rpn_loc: 0.08007    time: 1.2371  last_time: 1.1988  data_time: 0.0459  last_data_time: 0.0387   lr: 8.991e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:19:03 d2.utils.events]: \u001b[0m eta: 1:54:04  iter: 379  total_loss: 0.4039  loss_cls: 0.1535  loss_box_reg: 0.1151  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.07086    time: 1.2354  last_time: 1.2116  data_time: 0.0459  last_data_time: 0.0452   lr: 9.4905e-05  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:19:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:19:30 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:19:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:19:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:19:30 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:19:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:19:30 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:19:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0009 s/iter. Inference: 0.0344 s/iter. Eval: 0.0002 s/iter. Total: 0.0354 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 14:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 149/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/06 14:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 288/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 14:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 427/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:35\n",
      "\u001b[32m[03/06 14:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 567/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 14:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 707/3060. Dataloading: 0.0011 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 14:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 834/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 14:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 974/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 14:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 1115/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 14:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 1255/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 1394/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 14:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 1524/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/06 14:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 1663/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:00:50\n",
      "\u001b[32m[03/06 14:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 1801/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/06 14:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 1938/3060. Dataloading: 0.0012 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/06 14:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 2073/3060. Dataloading: 0.0012 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/06 14:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 2207/3060. Dataloading: 0.0012 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:31\n",
      "\u001b[32m[03/06 14:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 2343/3060. Dataloading: 0.0012 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/06 14:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 2475/3060. Dataloading: 0.0012 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/06 14:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 2599/3060. Dataloading: 0.0012 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 2733/3060. Dataloading: 0.0012 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:00:12\n",
      "\u001b[32m[03/06 14:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 2856/3060. Dataloading: 0.0012 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0370 s/iter. ETA=0:00:07\n",
      "\u001b[32m[03/06 14:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 2985/3060. Dataloading: 0.0012 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:00:02\n",
      "\u001b[32m[03/06 14:21:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:53.432355 (0.037130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:21:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:48 (0.035654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:21:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:21:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:21:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.98s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
      "\u001b[32m[03/06 14:21:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.686 | 1.751  | 0.355  | 0.001 | 0.419 | 0.904 |\n",
      "\u001b[32m[03/06 14:21:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.058 | bus        | 0.012 |\n",
      "| car        | 4.349 | construction equipment | 0.232 | emergency  | 0.740 |\n",
      "| motorbike  | 0.002 | personal mobility      | 0.000 | quad bike  | 0.777 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:21:29 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:21:29 d2.evaluation.testing]: \u001b[0mcopypaste: 0.6856,1.7506,0.3545,0.0012,0.4186,0.9039\n",
      "\u001b[32m[03/06 14:21:29 d2.utils.events]: \u001b[0m eta: 1:53:31  iter: 399  total_loss: 0.3926  loss_cls: 0.1466  loss_box_reg: 0.1122  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.05254    time: 1.2336  last_time: 1.2133  data_time: 0.0494  last_data_time: 0.0503   lr: 9.99e-05  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:21:57 d2.utils.events]: \u001b[0m eta: 1:53:06  iter: 419  total_loss: 0.4246  loss_cls: 0.1515  loss_box_reg: 0.1185  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.07143    time: 1.2330  last_time: 1.2059  data_time: 0.0440  last_data_time: 0.0382   lr: 0.0001049  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:22:25 d2.utils.events]: \u001b[0m eta: 1:52:40  iter: 439  total_loss: 0.3677  loss_cls: 0.1494  loss_box_reg: 0.1161  loss_rpn_cls: 0.05075  loss_rpn_loc: 0.05009    time: 1.2321  last_time: 1.1932  data_time: 0.0437  last_data_time: 0.0356   lr: 0.00010989  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:22:54 d2.utils.events]: \u001b[0m eta: 1:52:18  iter: 459  total_loss: 0.3895  loss_cls: 0.1433  loss_box_reg: 0.1184  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.05737    time: 1.2317  last_time: 1.2107  data_time: 0.0438  last_data_time: 0.0347   lr: 0.00011489  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:23:22 d2.utils.events]: \u001b[0m eta: 1:51:58  iter: 479  total_loss: 0.3726  loss_cls: 0.1481  loss_box_reg: 0.1208  loss_rpn_cls: 0.04959  loss_rpn_loc: 0.04536    time: 1.2313  last_time: 1.2082  data_time: 0.0461  last_data_time: 0.0424   lr: 0.00011988  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:23:50 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:23:50 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:23:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:23:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:23:50 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:23:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:23:50 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:23:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0005 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:02\n",
      "\u001b[32m[03/06 14:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 143/3060. Dataloading: 0.0013 s/iter. Inference: 0.0366 s/iter. Eval: 0.0002 s/iter. Total: 0.0382 s/iter. ETA=0:01:51\n",
      "\u001b[32m[03/06 14:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 278/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:01:44\n",
      "\u001b[32m[03/06 14:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 439/3060. Dataloading: 0.0012 s/iter. Inference: 0.0338 s/iter. Eval: 0.0002 s/iter. Total: 0.0352 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 14:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 595/3060. Dataloading: 0.0012 s/iter. Inference: 0.0330 s/iter. Eval: 0.0002 s/iter. Total: 0.0344 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 14:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 756/3060. Dataloading: 0.0012 s/iter. Inference: 0.0323 s/iter. Eval: 0.0002 s/iter. Total: 0.0337 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 14:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 917/3060. Dataloading: 0.0012 s/iter. Inference: 0.0318 s/iter. Eval: 0.0002 s/iter. Total: 0.0333 s/iter. ETA=0:01:11\n",
      "\u001b[32m[03/06 14:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 1077/3060. Dataloading: 0.0012 s/iter. Inference: 0.0315 s/iter. Eval: 0.0002 s/iter. Total: 0.0330 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 1233/3060. Dataloading: 0.0012 s/iter. Inference: 0.0314 s/iter. Eval: 0.0002 s/iter. Total: 0.0329 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 14:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 1391/3060. Dataloading: 0.0012 s/iter. Inference: 0.0313 s/iter. Eval: 0.0002 s/iter. Total: 0.0327 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 14:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 1549/3060. Dataloading: 0.0012 s/iter. Inference: 0.0312 s/iter. Eval: 0.0002 s/iter. Total: 0.0326 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 14:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 1705/3060. Dataloading: 0.0012 s/iter. Inference: 0.0311 s/iter. Eval: 0.0002 s/iter. Total: 0.0326 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/06 14:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 1865/3060. Dataloading: 0.0012 s/iter. Inference: 0.0310 s/iter. Eval: 0.0002 s/iter. Total: 0.0325 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 14:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 2025/3060. Dataloading: 0.0012 s/iter. Inference: 0.0309 s/iter. Eval: 0.0002 s/iter. Total: 0.0324 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 14:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 2187/3060. Dataloading: 0.0012 s/iter. Inference: 0.0308 s/iter. Eval: 0.0002 s/iter. Total: 0.0323 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 14:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 2348/3060. Dataloading: 0.0012 s/iter. Inference: 0.0307 s/iter. Eval: 0.0002 s/iter. Total: 0.0322 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/06 14:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 2510/3060. Dataloading: 0.0012 s/iter. Inference: 0.0306 s/iter. Eval: 0.0002 s/iter. Total: 0.0321 s/iter. ETA=0:00:17\n",
      "\u001b[32m[03/06 14:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 2668/3060. Dataloading: 0.0012 s/iter. Inference: 0.0306 s/iter. Eval: 0.0002 s/iter. Total: 0.0321 s/iter. ETA=0:00:12\n",
      "\u001b[32m[03/06 14:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 2821/3060. Dataloading: 0.0012 s/iter. Inference: 0.0306 s/iter. Eval: 0.0002 s/iter. Total: 0.0322 s/iter. ETA=0:00:07\n",
      "\u001b[32m[03/06 14:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 2979/3060. Dataloading: 0.0012 s/iter. Inference: 0.0306 s/iter. Eval: 0.0002 s/iter. Total: 0.0321 s/iter. ETA=0:00:02\n",
      "\u001b[32m[03/06 14:25:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:38.309519 (0.032180 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:25:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:33 (0.030642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:25:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:25:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:25:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.93s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126\n",
      "\u001b[32m[03/06 14:25:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.000 | 2.726  | 0.389  | 0.004 | 0.542 | 1.345 |\n",
      "\u001b[32m[03/06 14:25:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.133 | bus        | 0.015 |\n",
      "| car        | 5.892 | construction equipment | 0.271 | emergency  | 1.122 |\n",
      "| motorbike  | 0.001 | personal mobility      | 0.000 | quad bike  | 1.563 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:25:34 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.9996,2.7264,0.3890,0.0037,0.5420,1.3454\n",
      "\u001b[32m[03/06 14:25:34 d2.utils.events]: \u001b[0m eta: 1:51:34  iter: 499  total_loss: 0.4329  loss_cls: 0.1465  loss_box_reg: 0.12  loss_rpn_cls: 0.05608  loss_rpn_loc: 0.07114    time: 1.2311  last_time: 1.2171  data_time: 0.0447  last_data_time: 0.0441   lr: 0.00012488  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:26:01 d2.utils.events]: \u001b[0m eta: 1:51:06  iter: 519  total_loss: 0.3842  loss_cls: 0.1414  loss_box_reg: 0.1127  loss_rpn_cls: 0.05502  loss_rpn_loc: 0.06375    time: 1.2300  last_time: 1.2064  data_time: 0.0539  last_data_time: 0.0556   lr: 0.00012987  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:26:29 d2.utils.events]: \u001b[0m eta: 1:50:39  iter: 539  total_loss: 0.3765  loss_cls: 0.1371  loss_box_reg: 0.1122  loss_rpn_cls: 0.05667  loss_rpn_loc: 0.06166    time: 1.2295  last_time: 1.2023  data_time: 0.0547  last_data_time: 0.0535   lr: 0.00013487  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:26:56 d2.utils.events]: \u001b[0m eta: 1:50:10  iter: 559  total_loss: 0.3624  loss_cls: 0.1334  loss_box_reg: 0.1168  loss_rpn_cls: 0.054  loss_rpn_loc: 0.0643    time: 1.2283  last_time: 1.2111  data_time: 0.0538  last_data_time: 0.0535   lr: 0.00013986  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:27:24 d2.utils.events]: \u001b[0m eta: 1:49:46  iter: 579  total_loss: 0.3819  loss_cls: 0.1307  loss_box_reg: 0.1169  loss_rpn_cls: 0.058  loss_rpn_loc: 0.07529    time: 1.2280  last_time: 1.2102  data_time: 0.0554  last_data_time: 0.0631   lr: 0.00014486  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:27:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:27:52 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:27:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:27:53 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:27:53 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:27:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:27:53 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:27:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0003 s/iter. Inference: 0.0290 s/iter. Eval: 0.0002 s/iter. Total: 0.0295 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 14:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 175/3060. Dataloading: 0.0011 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0305 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 14:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 339/3060. Dataloading: 0.0011 s/iter. Inference: 0.0292 s/iter. Eval: 0.0002 s/iter. Total: 0.0305 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 14:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 500/3060. Dataloading: 0.0012 s/iter. Inference: 0.0293 s/iter. Eval: 0.0002 s/iter. Total: 0.0307 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/06 14:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 662/3060. Dataloading: 0.0012 s/iter. Inference: 0.0294 s/iter. Eval: 0.0002 s/iter. Total: 0.0308 s/iter. ETA=0:01:13\n",
      "\u001b[32m[03/06 14:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 813/3060. Dataloading: 0.0012 s/iter. Inference: 0.0298 s/iter. Eval: 0.0002 s/iter. Total: 0.0312 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 14:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 968/3060. Dataloading: 0.0012 s/iter. Inference: 0.0299 s/iter. Eval: 0.0002 s/iter. Total: 0.0314 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 1125/3060. Dataloading: 0.0012 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 14:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 1283/3060. Dataloading: 0.0012 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/06 14:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 1439/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0316 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/06 14:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 1598/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0316 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/06 14:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 1758/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0316 s/iter. ETA=0:00:41\n",
      "\u001b[32m[03/06 14:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 1920/3060. Dataloading: 0.0012 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 14:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 2079/3060. Dataloading: 0.0012 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/06 14:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 2221/3060. Dataloading: 0.0012 s/iter. Inference: 0.0303 s/iter. Eval: 0.0002 s/iter. Total: 0.0318 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/06 14:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 2383/3060. Dataloading: 0.0012 s/iter. Inference: 0.0302 s/iter. Eval: 0.0002 s/iter. Total: 0.0317 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/06 14:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 2546/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0316 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 2709/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0316 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/06 14:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 2872/3060. Dataloading: 0.0012 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:00:05\n",
      "\u001b[32m[03/06 14:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 3036/3060. Dataloading: 0.0012 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0315 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/06 14:29:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:36.267222 (0.031511 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:29:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:31 (0.030005 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:29:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:29:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:29:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
      "\u001b[32m[03/06 14:29:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.360 | 3.732  | 0.557  | 0.003 | 0.689 | 1.828 |\n",
      "\u001b[32m[03/06 14:29:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category               | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan   | bike                   | 0.529 | bus        | 0.015 |\n",
      "| car        | 7.219 | construction equipment | 0.365 | emergency  | 1.685 |\n",
      "| motorbike  | 0.002 | personal mobility      | 0.000 | quad bike  | 2.425 |\n",
      "| truck      | 0.000 |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:29:35 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:29:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:29:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:29:35 d2.evaluation.testing]: \u001b[0mcopypaste: 1.3600,3.7318,0.5567,0.0031,0.6891,1.8284\n",
      "\u001b[32m[03/06 14:29:35 d2.utils.events]: \u001b[0m eta: 1:49:24  iter: 599  total_loss: 0.3782  loss_cls: 0.1326  loss_box_reg: 0.1204  loss_rpn_cls: 0.04995  loss_rpn_loc: 0.05736    time: 1.2280  last_time: 1.2103  data_time: 0.0600  last_data_time: 0.0598   lr: 0.00014985  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:30:03 d2.utils.events]: \u001b[0m eta: 1:49:02  iter: 619  total_loss: 0.3713  loss_cls: 0.1447  loss_box_reg: 0.1242  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.05246    time: 1.2279  last_time: 1.2327  data_time: 0.0582  last_data_time: 0.0635   lr: 0.00015485  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:30:31 d2.utils.events]: \u001b[0m eta: 1:48:38  iter: 639  total_loss: 0.3742  loss_cls: 0.132  loss_box_reg: 0.1239  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.05062    time: 1.2275  last_time: 1.2249  data_time: 0.0558  last_data_time: 0.0687   lr: 0.00015984  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:30:58 d2.utils.events]: \u001b[0m eta: 1:48:11  iter: 659  total_loss: 0.3775  loss_cls: 0.1387  loss_box_reg: 0.1188  loss_rpn_cls: 0.04846  loss_rpn_loc: 0.06745    time: 1.2268  last_time: 1.2060  data_time: 0.0538  last_data_time: 0.0477   lr: 0.00016484  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:31:27 d2.utils.events]: \u001b[0m eta: 1:47:49  iter: 679  total_loss: 0.3626  loss_cls: 0.1413  loss_box_reg: 0.1305  loss_rpn_cls: 0.04049  loss_rpn_loc: 0.04277    time: 1.2272  last_time: 1.2303  data_time: 0.0540  last_data_time: 0.0502   lr: 0.00016983  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:31:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:31:54 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:31:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:31:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:31:55 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:31:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:31:55 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:31:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0293 s/iter. Eval: 0.0002 s/iter. Total: 0.0299 s/iter. ETA=0:01:31\n",
      "\u001b[32m[03/06 14:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 148/3060. Dataloading: 0.0012 s/iter. Inference: 0.0349 s/iter. Eval: 0.0003 s/iter. Total: 0.0364 s/iter. ETA=0:01:46\n",
      "\u001b[32m[03/06 14:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 288/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 14:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 428/3060. Dataloading: 0.0011 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/06 14:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 567/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 14:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 707/3060. Dataloading: 0.0011 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 14:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 847/3060. Dataloading: 0.0011 s/iter. Inference: 0.0346 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 14:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 985/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/06 14:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 1122/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 14:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 1259/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 1399/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 14:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 1534/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:55\n",
      "\u001b[32m[03/06 14:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 1674/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:50\n",
      "\u001b[32m[03/06 14:33:01 d2.evaluation.evaluator]: \u001b[0mInference done 1813/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/06 14:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 1954/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:39\n",
      "\u001b[32m[03/06 14:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 2092/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 14:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 2234/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:29\n",
      "\u001b[32m[03/06 14:33:21 d2.evaluation.evaluator]: \u001b[0mInference done 2371/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 14:33:26 d2.evaluation.evaluator]: \u001b[0mInference done 2494/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/06 14:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 2634/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:00:15\n",
      "\u001b[32m[03/06 14:33:36 d2.evaluation.evaluator]: \u001b[0mInference done 2775/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:00:10\n",
      "\u001b[32m[03/06 14:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 2911/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:00:05\n",
      "\u001b[32m[03/06 14:33:46 d2.evaluation.evaluator]: \u001b[0mInference done 3053/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/06 14:33:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:50.972944 (0.036325 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:33:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:46 (0.034935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:33:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:33:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:33:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      "\u001b[32m[03/06 14:33:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.771 | 4.707  | 0.688  | 0.007 | 0.942 | 2.467 |\n",
      "\u001b[32m[03/06 14:33:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP    |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan    | bike                   | 1.583 | bus        | 0.014 |\n",
      "| car        | 10.019 | construction equipment | 0.382 | emergency  | 2.052 |\n",
      "| motorbike  | 0.012  | personal mobility      | 0.000 | quad bike  | 1.875 |\n",
      "| truck      | 0.000  |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:33:53 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:33:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:33:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:33:53 d2.evaluation.testing]: \u001b[0mcopypaste: 1.7706,4.7070,0.6879,0.0068,0.9421,2.4675\n",
      "\u001b[32m[03/06 14:33:53 d2.utils.events]: \u001b[0m eta: 1:47:26  iter: 699  total_loss: 0.364  loss_cls: 0.1354  loss_box_reg: 0.1219  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.04584    time: 1.2270  last_time: 1.2264  data_time: 0.0450  last_data_time: 0.0497   lr: 0.00017483  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:34:20 d2.utils.events]: \u001b[0m eta: 1:47:00  iter: 719  total_loss: 0.3509  loss_cls: 0.1342  loss_box_reg: 0.1258  loss_rpn_cls: 0.04301  loss_rpn_loc: 0.05126    time: 1.2266  last_time: 1.2134  data_time: 0.0436  last_data_time: 0.0414   lr: 0.00017982  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:34:48 d2.utils.events]: \u001b[0m eta: 1:46:38  iter: 739  total_loss: 0.3672  loss_cls: 0.1336  loss_box_reg: 0.1209  loss_rpn_cls: 0.04682  loss_rpn_loc: 0.04689    time: 1.2266  last_time: 1.2247  data_time: 0.0465  last_data_time: 0.0549   lr: 0.00018482  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:35:16 d2.utils.events]: \u001b[0m eta: 1:46:15  iter: 759  total_loss: 0.3268  loss_cls: 0.1317  loss_box_reg: 0.1228  loss_rpn_cls: 0.04424  loss_rpn_loc: 0.04593    time: 1.2266  last_time: 1.2136  data_time: 0.0483  last_data_time: 0.0440   lr: 0.00018981  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:35:45 d2.utils.events]: \u001b[0m eta: 1:45:52  iter: 779  total_loss: 0.4162  loss_cls: 0.1304  loss_box_reg: 0.1166  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.08532    time: 1.2269  last_time: 1.2275  data_time: 0.0453  last_data_time: 0.0469   lr: 0.00019481  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:36:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:36:13 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:36:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:36:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:36:13 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:36:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:36:13 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:36:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:01:53\n",
      "\u001b[32m[03/06 14:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 147/3060. Dataloading: 0.0010 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:01:47\n",
      "\u001b[32m[03/06 14:36:24 d2.evaluation.evaluator]: \u001b[0mInference done 284/3060. Dataloading: 0.0010 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:01:42\n",
      "\u001b[32m[03/06 14:36:29 d2.evaluation.evaluator]: \u001b[0mInference done 422/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 14:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 560/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:31\n",
      "\u001b[32m[03/06 14:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 699/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:26\n",
      "\u001b[32m[03/06 14:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 834/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 14:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 973/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:16\n",
      "\u001b[32m[03/06 14:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 1110/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:11\n",
      "\u001b[32m[03/06 14:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 1248/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/06 14:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 1385/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 14:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 1521/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/06 14:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 1657/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/06 14:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 1799/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/06 14:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 1936/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:41\n",
      "\u001b[32m[03/06 14:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 2067/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/06 14:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 2204/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:31\n",
      "\u001b[32m[03/06 14:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 2343/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/06 14:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 2470/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/06 14:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 2607/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 2740/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/06 14:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 2872/3060. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/06 14:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 3010/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:00:01\n",
      "\u001b[32m[03/06 14:38:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:52.440018 (0.036805 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:38:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:48 (0.035423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:38:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:38:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:38:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      "\u001b[32m[03/06 14:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.253 | 5.707  | 1.145  | 0.007 | 1.200 | 3.127 |\n",
      "\u001b[32m[03/06 14:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP    |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan    | bike                   | 2.117 | bus        | 0.006 |\n",
      "| car        | 12.520 | construction equipment | 0.462 | emergency  | 3.403 |\n",
      "| motorbike  | 0.013  | personal mobility      | 0.000 | quad bike  | 1.758 |\n",
      "| truck      | 0.000  |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2532,5.7068,1.1447,0.0067,1.2004,3.1275\n",
      "\u001b[32m[03/06 14:38:12 d2.utils.events]: \u001b[0m eta: 1:45:30  iter: 799  total_loss: 0.3636  loss_cls: 0.1356  loss_box_reg: 0.125  loss_rpn_cls: 0.04458  loss_rpn_loc: 0.04431    time: 1.2270  last_time: 1.2268  data_time: 0.0440  last_data_time: 0.0466   lr: 0.0001998  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:38:40 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 819  total_loss: 0.3489  loss_cls: 0.1377  loss_box_reg: 0.1282  loss_rpn_cls: 0.03399  loss_rpn_loc: 0.03757    time: 1.2272  last_time: 1.2295  data_time: 0.0465  last_data_time: 0.0460   lr: 0.0002048  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:39:08 d2.utils.events]: \u001b[0m eta: 1:44:44  iter: 839  total_loss: 0.3865  loss_cls: 0.1394  loss_box_reg: 0.1279  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.062    time: 1.2273  last_time: 1.2326  data_time: 0.0425  last_data_time: 0.0462   lr: 0.00020979  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:39:36 d2.utils.events]: \u001b[0m eta: 1:44:22  iter: 859  total_loss: 0.3894  loss_cls: 0.141  loss_box_reg: 0.1245  loss_rpn_cls: 0.05075  loss_rpn_loc: 0.05283    time: 1.2273  last_time: 1.2199  data_time: 0.0449  last_data_time: 0.0439   lr: 0.00021479  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:40:04 d2.utils.events]: \u001b[0m eta: 1:43:59  iter: 879  total_loss: 0.3316  loss_cls: 0.1268  loss_box_reg: 0.1262  loss_rpn_cls: 0.03812  loss_rpn_loc: 0.04403    time: 1.2273  last_time: 1.2141  data_time: 0.0464  last_data_time: 0.0390   lr: 0.00021978  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:40:33 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:40:33 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:40:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:40:33 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:40:33 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:40:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:40:33 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:40:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0009 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0398 s/iter. ETA=0:02:01\n",
      "\u001b[32m[03/06 14:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 149/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/06 14:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 286/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:41\n",
      "\u001b[32m[03/06 14:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 424/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 14:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 563/3060. Dataloading: 0.0011 s/iter. Inference: 0.0350 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 14:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 700/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:01:26\n",
      "\u001b[32m[03/06 14:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 838/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 14:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 976/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 14:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 1109/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:11\n",
      "\u001b[32m[03/06 14:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 1247/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/06 14:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 1385/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 14:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 1521/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/06 14:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 1660/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/06 14:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 1798/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/06 14:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 1933/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:41\n",
      "\u001b[32m[03/06 14:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 2070/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/06 14:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 2207/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:31\n",
      "\u001b[32m[03/06 14:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 2341/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/06 14:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 2473/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/06 14:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 2606/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 2745/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/06 14:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 2885/3060. Dataloading: 0.0011 s/iter. Inference: 0.0353 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/06 14:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 3024/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:01\n",
      "\u001b[32m[03/06 14:42:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.880835 (0.036622 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:42:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:47 (0.035199 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:42:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:42:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:42:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.99s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.43s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      "\u001b[32m[03/06 14:42:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.831 | 6.747  | 1.684  | 0.010 | 1.470 | 3.950 |\n",
      "\u001b[32m[03/06 14:42:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP    |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan    | bike                   | 3.249 | bus        | 0.000 |\n",
      "| car        | 14.976 | construction equipment | 0.659 | emergency  | 5.265 |\n",
      "| motorbike  | 0.039  | personal mobility      | 0.000 | quad bike  | 1.291 |\n",
      "| truck      | 0.000  |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:42:32 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:42:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:42:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:42:32 d2.evaluation.testing]: \u001b[0mcopypaste: 2.8310,6.7466,1.6836,0.0100,1.4698,3.9497\n",
      "\u001b[32m[03/06 14:42:32 d2.utils.events]: \u001b[0m eta: 1:43:35  iter: 899  total_loss: 0.365  loss_cls: 0.1206  loss_box_reg: 0.1117  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.06055    time: 1.2272  last_time: 1.2102  data_time: 0.0458  last_data_time: 0.0502   lr: 0.00022478  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:43:00 d2.utils.events]: \u001b[0m eta: 1:43:13  iter: 919  total_loss: 0.3461  loss_cls: 0.1245  loss_box_reg: 0.1165  loss_rpn_cls: 0.04169  loss_rpn_loc: 0.05406    time: 1.2272  last_time: 1.2322  data_time: 0.0484  last_data_time: 0.0486   lr: 0.00022977  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:43:28 d2.utils.events]: \u001b[0m eta: 1:42:50  iter: 939  total_loss: 0.3676  loss_cls: 0.1307  loss_box_reg: 0.1228  loss_rpn_cls: 0.04487  loss_rpn_loc: 0.06324    time: 1.2271  last_time: 1.2461  data_time: 0.0475  last_data_time: 0.0496   lr: 0.00023477  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:43:56 d2.utils.events]: \u001b[0m eta: 1:42:26  iter: 959  total_loss: 0.3256  loss_cls: 0.1194  loss_box_reg: 0.1162  loss_rpn_cls: 0.04047  loss_rpn_loc: 0.04338    time: 1.2273  last_time: 1.2978  data_time: 0.0535  last_data_time: 0.0670   lr: 0.00023976  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:44:26 d2.utils.events]: \u001b[0m eta: 1:42:05  iter: 979  total_loss: 0.3363  loss_cls: 0.1312  loss_box_reg: 0.1279  loss_rpn_cls: 0.03576  loss_rpn_loc: 0.04173    time: 1.2282  last_time: 1.2809  data_time: 0.0609  last_data_time: 0.1064   lr: 0.00024476  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:44:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:44:54 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:44:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:44:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:44:54 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:44:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:44:54 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:44:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0011 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0305 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 14:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 145/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 14:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 280/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 14:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 415/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:01:38\n",
      "\u001b[32m[03/06 14:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 553/3060. Dataloading: 0.0011 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0370 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 14:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 691/3060. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 14:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 827/3060. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:01:22\n",
      "\u001b[32m[03/06 14:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 964/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 14:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 1090/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:01:13\n",
      "\u001b[32m[03/06 14:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 1226/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:01:08\n",
      "\u001b[32m[03/06 14:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 1363/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:01:02\n",
      "\u001b[32m[03/06 14:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 1497/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:00:58\n",
      "\u001b[32m[03/06 14:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 1636/3060. Dataloading: 0.0011 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0370 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/06 14:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 1763/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/06 14:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 1902/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:00:42\n",
      "\u001b[32m[03/06 14:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 2038/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:00:37\n",
      "\u001b[32m[03/06 14:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 2165/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 14:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 2287/3060. Dataloading: 0.0011 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0375 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 14:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 2410/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 14:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 2530/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/06 14:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 2652/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:00:15\n",
      "\u001b[32m[03/06 14:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 2775/3060. Dataloading: 0.0012 s/iter. Inference: 0.0366 s/iter. Eval: 0.0002 s/iter. Total: 0.0381 s/iter. ETA=0:00:10\n",
      "\u001b[32m[03/06 14:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 2902/3060. Dataloading: 0.0012 s/iter. Inference: 0.0367 s/iter. Eval: 0.0002 s/iter. Total: 0.0382 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/06 14:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 3024/3060. Dataloading: 0.0012 s/iter. Inference: 0.0368 s/iter. Eval: 0.0002 s/iter. Total: 0.0383 s/iter. ETA=0:00:01\n",
      "\u001b[32m[03/06 14:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:56.896604 (0.038264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:52 (0.036761 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:46:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:46:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:46:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.31s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      "\u001b[32m[03/06 14:46:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 3.523 | 8.435  | 2.132  | 0.017 | 1.727 | 4.831 |\n",
      "\u001b[32m[03/06 14:46:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP    |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:------|\n",
      "| cars       | nan    | bike                   | 3.672 | bus        | 0.000 |\n",
      "| car        | 17.936 | construction equipment | 0.664 | emergency  | 8.652 |\n",
      "| motorbike  | 0.122  | personal mobility      | 0.000 | quad bike  | 0.664 |\n",
      "| truck      | 0.000  |                        |       |            |       |\n",
      "\u001b[32m[03/06 14:46:59 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:46:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:46:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:46:59 d2.evaluation.testing]: \u001b[0mcopypaste: 3.5234,8.4348,2.1325,0.0167,1.7269,4.8305\n",
      "\u001b[32m[03/06 14:46:59 d2.utils.events]: \u001b[0m eta: 1:41:43  iter: 999  total_loss: 0.3699  loss_cls: 0.1306  loss_box_reg: 0.1292  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.04716    time: 1.2283  last_time: 1.2318  data_time: 0.0514  last_data_time: 0.0626   lr: 0.00024975  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:47:27 d2.utils.events]: \u001b[0m eta: 1:41:22  iter: 1019  total_loss: 0.3652  loss_cls: 0.1281  loss_box_reg: 0.1212  loss_rpn_cls: 0.04031  loss_rpn_loc: 0.06941    time: 1.2286  last_time: 1.2770  data_time: 0.0538  last_data_time: 0.0567   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:47:56 d2.utils.events]: \u001b[0m eta: 1:40:59  iter: 1039  total_loss: 0.3314  loss_cls: 0.1176  loss_box_reg: 0.1117  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.04779    time: 1.2288  last_time: 1.2379  data_time: 0.0547  last_data_time: 0.0539   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:48:25 d2.utils.events]: \u001b[0m eta: 1:40:37  iter: 1059  total_loss: 0.3284  loss_cls: 0.122  loss_box_reg: 0.12  loss_rpn_cls: 0.04028  loss_rpn_loc: 0.04884    time: 1.2290  last_time: 1.2360  data_time: 0.0523  last_data_time: 0.0510   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:48:53 d2.utils.events]: \u001b[0m eta: 1:40:14  iter: 1079  total_loss: 0.3378  loss_cls: 0.1246  loss_box_reg: 0.129  loss_rpn_cls: 0.0341  loss_rpn_loc: 0.04763    time: 1.2291  last_time: 1.2552  data_time: 0.0452  last_data_time: 0.0438   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:49:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:49:21 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:49:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:49:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:49:21 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:49:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:49:21 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:49:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0003 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0355 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 14:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 151/3060. Dataloading: 0.0011 s/iter. Inference: 0.0344 s/iter. Eval: 0.0002 s/iter. Total: 0.0357 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 14:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 291/3060. Dataloading: 0.0011 s/iter. Inference: 0.0344 s/iter. Eval: 0.0002 s/iter. Total: 0.0358 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/06 14:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 429/3060. Dataloading: 0.0011 s/iter. Inference: 0.0347 s/iter. Eval: 0.0002 s/iter. Total: 0.0360 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/06 14:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 567/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 14:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 704/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0362 s/iter. ETA=0:01:25\n",
      "\u001b[32m[03/06 14:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 840/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:20\n",
      "\u001b[32m[03/06 14:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 978/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 14:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 1117/3060. Dataloading: 0.0011 s/iter. Inference: 0.0349 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 14:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 1250/3060. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 14:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 1384/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 14:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 1518/3060. Dataloading: 0.0011 s/iter. Inference: 0.0352 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/06 14:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 1647/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/06 14:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 1770/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:00:47\n",
      "\u001b[32m[03/06 14:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 1898/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 14:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 2030/3060. Dataloading: 0.0012 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 14:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 2168/3060. Dataloading: 0.0012 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 14:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 2295/3060. Dataloading: 0.0012 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 14:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 2426/3060. Dataloading: 0.0012 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:23\n",
      "\u001b[32m[03/06 14:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 2561/3060. Dataloading: 0.0012 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:18\n",
      "\u001b[32m[03/06 14:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 2697/3060. Dataloading: 0.0012 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 14:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 2828/3060. Dataloading: 0.0012 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 14:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 2959/3060. Dataloading: 0.0012 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0375 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 14:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:54.742999 (0.037559 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.036071 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:51:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:51:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:51:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.32s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      "\u001b[32m[03/06 14:51:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.574 | 10.489 | 3.117  | 0.015 | 2.021 | 6.142 |\n",
      "\u001b[32m[03/06 14:51:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 4.510 | bus        | 0.000  |\n",
      "| car        | 20.403 | construction equipment | 0.798 | emergency  | 14.308 |\n",
      "| motorbike  | 0.552  | personal mobility      | 0.000 | quad bike  | 0.598  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 14:51:23 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:51:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:51:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:51:23 d2.evaluation.testing]: \u001b[0mcopypaste: 4.5744,10.4887,3.1169,0.0145,2.0210,6.1420\n",
      "\u001b[32m[03/06 14:51:23 d2.utils.events]: \u001b[0m eta: 1:39:51  iter: 1099  total_loss: 0.3532  loss_cls: 0.1256  loss_box_reg: 0.1281  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.05099    time: 1.2289  last_time: 1.2139  data_time: 0.0442  last_data_time: 0.0373   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:51:51 d2.utils.events]: \u001b[0m eta: 1:39:27  iter: 1119  total_loss: 0.326  loss_cls: 0.1132  loss_box_reg: 0.1204  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.04921    time: 1.2289  last_time: 1.2208  data_time: 0.0542  last_data_time: 0.0450   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:52:19 d2.utils.events]: \u001b[0m eta: 1:39:04  iter: 1139  total_loss: 0.3272  loss_cls: 0.1188  loss_box_reg: 0.1247  loss_rpn_cls: 0.04027  loss_rpn_loc: 0.04228    time: 1.2289  last_time: 1.2433  data_time: 0.0488  last_data_time: 0.0593   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:52:47 d2.utils.events]: \u001b[0m eta: 1:38:39  iter: 1159  total_loss: 0.3573  loss_cls: 0.1184  loss_box_reg: 0.12  loss_rpn_cls: 0.04089  loss_rpn_loc: 0.04763    time: 1.2291  last_time: 1.2247  data_time: 0.0521  last_data_time: 0.0558   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:53:16 d2.utils.events]: \u001b[0m eta: 1:38:13  iter: 1179  total_loss: 0.3224  loss_cls: 0.1116  loss_box_reg: 0.1157  loss_rpn_cls: 0.0327  loss_rpn_loc: 0.03661    time: 1.2291  last_time: 1.2235  data_time: 0.0486  last_data_time: 0.0471   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:53:45 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:53:45 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:53:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:53:45 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:53:45 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:53:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:53:45 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:53:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0357 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 14:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 151/3060. Dataloading: 0.0011 s/iter. Inference: 0.0344 s/iter. Eval: 0.0002 s/iter. Total: 0.0357 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 14:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 288/3060. Dataloading: 0.0011 s/iter. Inference: 0.0348 s/iter. Eval: 0.0002 s/iter. Total: 0.0361 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 14:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 406/3060. Dataloading: 0.0012 s/iter. Inference: 0.0366 s/iter. Eval: 0.0002 s/iter. Total: 0.0381 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 14:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 528/3060. Dataloading: 0.0012 s/iter. Inference: 0.0372 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:01:38\n",
      "\u001b[32m[03/06 14:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 645/3060. Dataloading: 0.0012 s/iter. Inference: 0.0380 s/iter. Eval: 0.0002 s/iter. Total: 0.0395 s/iter. ETA=0:01:35\n",
      "\u001b[32m[03/06 14:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 766/3060. Dataloading: 0.0013 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0398 s/iter. ETA=0:01:31\n",
      "\u001b[32m[03/06 14:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 886/3060. Dataloading: 0.0013 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0401 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 14:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 1005/3060. Dataloading: 0.0013 s/iter. Inference: 0.0388 s/iter. Eval: 0.0003 s/iter. Total: 0.0404 s/iter. ETA=0:01:22\n",
      "\u001b[32m[03/06 14:54:31 d2.evaluation.evaluator]: \u001b[0mInference done 1123/3060. Dataloading: 0.0013 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0406 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/06 14:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 1249/3060. Dataloading: 0.0013 s/iter. Inference: 0.0389 s/iter. Eval: 0.0003 s/iter. Total: 0.0405 s/iter. ETA=0:01:13\n",
      "\u001b[32m[03/06 14:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 1379/3060. Dataloading: 0.0013 s/iter. Inference: 0.0387 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/06 14:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 1518/3060. Dataloading: 0.0013 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0399 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 14:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 1656/3060. Dataloading: 0.0013 s/iter. Inference: 0.0380 s/iter. Eval: 0.0002 s/iter. Total: 0.0396 s/iter. ETA=0:00:55\n",
      "\u001b[32m[03/06 14:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 1796/3060. Dataloading: 0.0012 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 14:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 1936/3060. Dataloading: 0.0012 s/iter. Inference: 0.0375 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 14:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 2078/3060. Dataloading: 0.0012 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 14:55:11 d2.evaluation.evaluator]: \u001b[0mInference done 2215/3060. Dataloading: 0.0012 s/iter. Inference: 0.0372 s/iter. Eval: 0.0002 s/iter. Total: 0.0387 s/iter. ETA=0:00:32\n",
      "\u001b[32m[03/06 14:55:16 d2.evaluation.evaluator]: \u001b[0mInference done 2343/3060. Dataloading: 0.0012 s/iter. Inference: 0.0372 s/iter. Eval: 0.0002 s/iter. Total: 0.0387 s/iter. ETA=0:00:27\n",
      "\u001b[32m[03/06 14:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 2481/3060. Dataloading: 0.0012 s/iter. Inference: 0.0371 s/iter. Eval: 0.0002 s/iter. Total: 0.0386 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/06 14:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 2619/3060. Dataloading: 0.0012 s/iter. Inference: 0.0370 s/iter. Eval: 0.0002 s/iter. Total: 0.0385 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/06 14:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 2761/3060. Dataloading: 0.0012 s/iter. Inference: 0.0368 s/iter. Eval: 0.0002 s/iter. Total: 0.0383 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/06 14:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 2902/3060. Dataloading: 0.0012 s/iter. Inference: 0.0367 s/iter. Eval: 0.0002 s/iter. Total: 0.0382 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/06 14:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 3035/3060. Dataloading: 0.0012 s/iter. Inference: 0.0367 s/iter. Eval: 0.0002 s/iter. Total: 0.0381 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/06 14:55:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:56.745537 (0.038215 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:55:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:52 (0.036700 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 14:55:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 14:55:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 14:55:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.96s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "\u001b[32m[03/06 14:55:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 5.404 | 12.107 | 3.740  | 0.015 | 2.234 | 7.229 |\n",
      "\u001b[32m[03/06 14:55:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 5.897 | bus        | 0.000  |\n",
      "| car        | 22.971 | construction equipment | 0.856 | emergency  | 17.259 |\n",
      "| motorbike  | 0.875  | personal mobility      | 0.000 | quad bike  | 0.780  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 14:55:48 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 14:55:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 14:55:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 14:55:48 d2.evaluation.testing]: \u001b[0mcopypaste: 5.4042,12.1065,3.7403,0.0147,2.2338,7.2287\n",
      "\u001b[32m[03/06 14:55:48 d2.utils.events]: \u001b[0m eta: 1:37:48  iter: 1199  total_loss: 0.3141  loss_cls: 0.1153  loss_box_reg: 0.1129  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.04281    time: 1.2293  last_time: 1.2103  data_time: 0.0557  last_data_time: 0.0498   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:56:17 d2.utils.events]: \u001b[0m eta: 1:37:23  iter: 1219  total_loss: 0.3174  loss_cls: 0.1162  loss_box_reg: 0.1208  loss_rpn_cls: 0.0307  loss_rpn_loc: 0.03176    time: 1.2297  last_time: 1.3927  data_time: 0.0543  last_data_time: 0.0809   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:56:45 d2.utils.events]: \u001b[0m eta: 1:36:58  iter: 1239  total_loss: 0.3241  loss_cls: 0.1152  loss_box_reg: 0.12  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.0538    time: 1.2299  last_time: 1.2197  data_time: 0.0525  last_data_time: 0.0422   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:57:14 d2.utils.events]: \u001b[0m eta: 1:36:32  iter: 1259  total_loss: 0.3307  loss_cls: 0.1216  loss_box_reg: 0.1208  loss_rpn_cls: 0.03391  loss_rpn_loc: 0.04896    time: 1.2301  last_time: 1.2770  data_time: 0.0575  last_data_time: 0.0805   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 14:57:43 d2.utils.events]: \u001b[0m eta: 1:36:08  iter: 1279  total_loss: 0.3165  loss_cls: 0.1132  loss_box_reg: 0.1185  loss_rpn_cls: 0.03259  loss_rpn_loc: 0.05091    time: 1.2302  last_time: 1.2153  data_time: 0.0532  last_data_time: 0.0472   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 14:58:11 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 14:58:11 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 14:58:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 14:58:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 14:58:11 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 14:58:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 14:58:11 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 14:58:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 14:58:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0395 s/iter. ETA=0:02:00\n",
      "\u001b[32m[03/06 14:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 145/3060. Dataloading: 0.0010 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:01:49\n",
      "\u001b[32m[03/06 14:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 284/3060. Dataloading: 0.0011 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:01:42\n",
      "\u001b[32m[03/06 14:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 421/3060. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:01:37\n",
      "\u001b[32m[03/06 14:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 558/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:01:31\n",
      "\u001b[32m[03/06 14:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 695/3060. Dataloading: 0.0011 s/iter. Inference: 0.0354 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:01:26\n",
      "\u001b[32m[03/06 14:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 828/3060. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0369 s/iter. ETA=0:01:22\n",
      "\u001b[32m[03/06 14:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 960/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0370 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 14:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 1093/3060. Dataloading: 0.0011 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:01:12\n",
      "\u001b[32m[03/06 14:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 1227/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0371 s/iter. ETA=0:01:08\n",
      "\u001b[32m[03/06 14:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 1357/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:01:03\n",
      "\u001b[32m[03/06 14:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 1491/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:58\n",
      "\u001b[32m[03/06 14:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 1627/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:53\n",
      "\u001b[32m[03/06 14:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 1760/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/06 14:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 1892/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 14:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 2026/3060. Dataloading: 0.0011 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0374 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 14:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 2163/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 14:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 2299/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 14:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 2435/3060. Dataloading: 0.0011 s/iter. Inference: 0.0359 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:00:23\n",
      "\u001b[32m[03/06 14:59:47 d2.evaluation.evaluator]: \u001b[0mInference done 2574/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:18\n",
      "\u001b[32m[03/06 14:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 2710/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 14:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 2843/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 15:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 2978/3060. Dataloading: 0.0011 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 15:00:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:53.643644 (0.037199 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:00:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:49 (0.035762 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:00:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:00:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:00:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.99s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211\n",
      "\u001b[32m[03/06 15:00:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.371 | 13.359 | 5.035  | 0.013 | 2.581 | 8.422 |\n",
      "\u001b[32m[03/06 15:00:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 6.757 | bus        | 0.000  |\n",
      "| car        | 25.417 | construction equipment | 1.146 | emergency  | 21.883 |\n",
      "| motorbike  | 1.454  | personal mobility      | 0.028 | quad bike  | 0.656  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:00:11 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:00:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:00:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:00:11 d2.evaluation.testing]: \u001b[0mcopypaste: 6.3713,13.3588,5.0350,0.0125,2.5810,8.4223\n",
      "\u001b[32m[03/06 15:00:11 d2.utils.events]: \u001b[0m eta: 1:35:43  iter: 1299  total_loss: 0.33  loss_cls: 0.1149  loss_box_reg: 0.1183  loss_rpn_cls: 0.03875  loss_rpn_loc: 0.05014    time: 1.2301  last_time: 1.2138  data_time: 0.0475  last_data_time: 0.0444   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:00:39 d2.utils.events]: \u001b[0m eta: 1:35:21  iter: 1319  total_loss: 0.33  loss_cls: 0.1147  loss_box_reg: 0.1208  loss_rpn_cls: 0.03945  loss_rpn_loc: 0.05747    time: 1.2301  last_time: 1.2409  data_time: 0.0502  last_data_time: 0.0573   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:01:07 d2.utils.events]: \u001b[0m eta: 1:34:58  iter: 1339  total_loss: 0.3277  loss_cls: 0.1163  loss_box_reg: 0.1224  loss_rpn_cls: 0.03177  loss_rpn_loc: 0.05203    time: 1.2301  last_time: 1.2251  data_time: 0.0479  last_data_time: 0.0513   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:01:34 d2.utils.events]: \u001b[0m eta: 1:34:35  iter: 1359  total_loss: 0.3407  loss_cls: 0.1127  loss_box_reg: 0.1195  loss_rpn_cls: 0.0328  loss_rpn_loc: 0.04954    time: 1.2298  last_time: 1.2033  data_time: 0.0471  last_data_time: 0.0417   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:02:03 d2.utils.events]: \u001b[0m eta: 1:34:12  iter: 1379  total_loss: 0.3056  loss_cls: 0.1097  loss_box_reg: 0.1127  loss_rpn_cls: 0.03545  loss_rpn_loc: 0.04664    time: 1.2297  last_time: 1.2095  data_time: 0.0500  last_data_time: 0.0460   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:02:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:02:32 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:02:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:02:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:02:32 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:02:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:02:32 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:02:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0006 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:05\n",
      "\u001b[32m[03/06 15:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 134/3060. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0408 s/iter. ETA=0:01:59\n",
      "\u001b[32m[03/06 15:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 264/3060. Dataloading: 0.0013 s/iter. Inference: 0.0382 s/iter. Eval: 0.0002 s/iter. Total: 0.0398 s/iter. ETA=0:01:51\n",
      "\u001b[32m[03/06 15:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 385/3060. Dataloading: 0.0013 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:47\n",
      "\u001b[32m[03/06 15:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 510/3060. Dataloading: 0.0013 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:42\n",
      "\u001b[32m[03/06 15:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 641/3060. Dataloading: 0.0013 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0399 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 15:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 763/3060. Dataloading: 0.0013 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0401 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 15:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 883/3060. Dataloading: 0.0013 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/06 15:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 999/3060. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 15:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 1118/3060. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 15:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 1237/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/06 15:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 1359/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/06 15:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 1492/3060. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:03\n",
      "\u001b[32m[03/06 15:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 1612/3060. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 15:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 1732/3060. Dataloading: 0.0013 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 15:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 1854/3060. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 15:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 1977/3060. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/06 15:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 2093/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:39\n",
      "\u001b[32m[03/06 15:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 2202/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 15:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 2337/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:29\n",
      "\u001b[32m[03/06 15:04:13 d2.evaluation.evaluator]: \u001b[0mInference done 2467/3060. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 15:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 2581/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/06 15:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 2700/3060. Dataloading: 0.0013 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/06 15:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 2836/3060. Dataloading: 0.0013 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 15:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 2971/3060. Dataloading: 0.0013 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 15:04:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:04.156885 (0.040641 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:04:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:59 (0.039045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:04:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:04:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:04:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.99s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "\u001b[32m[03/06 15:04:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.848 | 14.146 | 5.705  | 0.024 | 2.856 | 9.185 |\n",
      "\u001b[32m[03/06 15:04:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 7.350 | bus        | 0.000  |\n",
      "| car        | 27.482 | construction equipment | 1.391 | emergency  | 22.536 |\n",
      "| motorbike  | 2.170  | personal mobility      | 0.082 | quad bike  | 0.625  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:04:41 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:04:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:04:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:04:41 d2.evaluation.testing]: \u001b[0mcopypaste: 6.8483,14.1463,5.7053,0.0236,2.8555,9.1845\n",
      "\u001b[32m[03/06 15:04:41 d2.utils.events]: \u001b[0m eta: 1:33:49  iter: 1399  total_loss: 0.3119  loss_cls: 0.11  loss_box_reg: 0.1244  loss_rpn_cls: 0.03154  loss_rpn_loc: 0.03974    time: 1.2299  last_time: 1.2314  data_time: 0.0531  last_data_time: 0.0488   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:05:10 d2.utils.events]: \u001b[0m eta: 1:33:26  iter: 1419  total_loss: 0.305  loss_cls: 0.1043  loss_box_reg: 0.1144  loss_rpn_cls: 0.0307  loss_rpn_loc: 0.03637    time: 1.2299  last_time: 1.2281  data_time: 0.0493  last_data_time: 0.0453   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:05:38 d2.utils.events]: \u001b[0m eta: 1:33:04  iter: 1439  total_loss: 0.3127  loss_cls: 0.1127  loss_box_reg: 0.1112  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.04595    time: 1.2300  last_time: 1.2192  data_time: 0.0497  last_data_time: 0.0517   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:06:06 d2.utils.events]: \u001b[0m eta: 1:32:39  iter: 1459  total_loss: 0.3148  loss_cls: 0.1124  loss_box_reg: 0.1153  loss_rpn_cls: 0.03421  loss_rpn_loc: 0.04689    time: 1.2299  last_time: 1.2106  data_time: 0.0456  last_data_time: 0.0349   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:06:34 d2.utils.events]: \u001b[0m eta: 1:32:15  iter: 1479  total_loss: 0.3092  loss_cls: 0.1076  loss_box_reg: 0.1096  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.0487    time: 1.2300  last_time: 1.2343  data_time: 0.0452  last_data_time: 0.0481   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:07:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:07:02 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:07:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:07:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:07:02 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:07:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:07:02 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:07:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0009 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0384 s/iter. ETA=0:01:57\n",
      "\u001b[32m[03/06 15:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 143/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/06 15:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 280/3060. Dataloading: 0.0012 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 15:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 418/3060. Dataloading: 0.0012 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0370 s/iter. ETA=0:01:37\n",
      "\u001b[32m[03/06 15:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 551/3060. Dataloading: 0.0012 s/iter. Inference: 0.0357 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:01:33\n",
      "\u001b[32m[03/06 15:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 684/3060. Dataloading: 0.0012 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:01:28\n",
      "\u001b[32m[03/06 15:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 814/3060. Dataloading: 0.0012 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0375 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 15:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 947/3060. Dataloading: 0.0012 s/iter. Inference: 0.0361 s/iter. Eval: 0.0002 s/iter. Total: 0.0375 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 15:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 1078/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/06 15:07:48 d2.evaluation.evaluator]: \u001b[0mInference done 1208/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/06 15:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 1340/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/06 15:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 1474/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 15:08:03 d2.evaluation.evaluator]: \u001b[0mInference done 1607/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 15:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 1741/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 15:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 1874/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/06 15:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 2007/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:39\n",
      "\u001b[32m[03/06 15:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 2141/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:34\n",
      "\u001b[32m[03/06 15:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 2277/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:29\n",
      "\u001b[32m[03/06 15:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 2412/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 15:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 2543/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/06 15:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 2678/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/06 15:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 2813/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 15:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 2943/3060. Dataloading: 0.0012 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 15:08:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:54.808993 (0.037581 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:08:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.036105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:08:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:08:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:08:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.89s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      "\u001b[32m[03/06 15:09:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 7.702 | 15.341 | 6.714  | 0.030 | 2.969 | 10.204 |\n",
      "\u001b[32m[03/06 15:09:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 8.080 | bus        | 0.000  |\n",
      "| car        | 29.478 | construction equipment | 1.621 | emergency  | 25.514 |\n",
      "| motorbike  | 2.807  | personal mobility      | 0.139 | quad bike  | 1.678  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:09:02 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:09:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:09:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:09:02 d2.evaluation.testing]: \u001b[0mcopypaste: 7.7020,15.3409,6.7142,0.0303,2.9689,10.2038\n",
      "\u001b[32m[03/06 15:09:02 d2.utils.events]: \u001b[0m eta: 1:31:51  iter: 1499  total_loss: 0.2877  loss_cls: 0.1063  loss_box_reg: 0.1104  loss_rpn_cls: 0.03121  loss_rpn_loc: 0.04088    time: 1.2299  last_time: 1.2070  data_time: 0.0447  last_data_time: 0.0443   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:09:30 d2.utils.events]: \u001b[0m eta: 1:31:27  iter: 1519  total_loss: 0.2984  loss_cls: 0.1109  loss_box_reg: 0.1104  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.04497    time: 1.2298  last_time: 1.2207  data_time: 0.0482  last_data_time: 0.0571   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:09:58 d2.utils.events]: \u001b[0m eta: 1:31:04  iter: 1539  total_loss: 0.3256  loss_cls: 0.1166  loss_box_reg: 0.1205  loss_rpn_cls: 0.03463  loss_rpn_loc: 0.04851    time: 1.2298  last_time: 1.2309  data_time: 0.0502  last_data_time: 0.0603   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:10:26 d2.utils.events]: \u001b[0m eta: 1:30:41  iter: 1559  total_loss: 0.3276  loss_cls: 0.1093  loss_box_reg: 0.1192  loss_rpn_cls: 0.03469  loss_rpn_loc: 0.04849    time: 1.2298  last_time: 1.2140  data_time: 0.0513  last_data_time: 0.0430   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:10:54 d2.utils.events]: \u001b[0m eta: 1:30:17  iter: 1579  total_loss: 0.3052  loss_cls: 0.1038  loss_box_reg: 0.1085  loss_rpn_cls: 0.02866  loss_rpn_loc: 0.04586    time: 1.2297  last_time: 1.2318  data_time: 0.0485  last_data_time: 0.0368   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:11:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:11:22 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:11:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:11:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:11:22 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:11:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:11:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:11:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0008 s/iter. Inference: 0.0358 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/06 15:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 143/3060. Dataloading: 0.0011 s/iter. Inference: 0.0366 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/06 15:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 276/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/06 15:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 407/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 15:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 540/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:01:35\n",
      "\u001b[32m[03/06 15:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 675/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 15:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 809/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 15:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 941/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:20\n",
      "\u001b[32m[03/06 15:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 1074/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 15:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 1207/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/06 15:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 1338/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:01:05\n",
      "\u001b[32m[03/06 15:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 1474/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 15:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 1606/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 15:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 1739/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 15:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 1868/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/06 15:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 1998/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/06 15:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 2125/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 15:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 2256/3060. Dataloading: 0.0012 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/06 15:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 2393/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:00:25\n",
      "\u001b[32m[03/06 15:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 2529/3060. Dataloading: 0.0012 s/iter. Inference: 0.0364 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/06 15:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 2667/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/06 15:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 2803/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 15:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 2935/3060. Dataloading: 0.0012 s/iter. Inference: 0.0363 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 15:13:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:55.424629 (0.037782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:13:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:50 (0.036287 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:13:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:13:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:13:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n",
      "\u001b[32m[03/06 15:13:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 8.401 | 16.606 | 7.520  | 0.064 | 3.203 | 11.219 |\n",
      "\u001b[32m[03/06 15:13:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 8.858 | bus        | 0.000  |\n",
      "| car        | 31.755 | construction equipment | 1.562 | emergency  | 26.324 |\n",
      "| motorbike  | 4.034  | personal mobility      | 0.715 | quad bike  | 2.363  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:13:24 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: 8.4013,16.6063,7.5204,0.0641,3.2029,11.2187\n",
      "\u001b[32m[03/06 15:13:24 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 1599  total_loss: 0.3116  loss_cls: 0.1087  loss_box_reg: 0.12  loss_rpn_cls: 0.03315  loss_rpn_loc: 0.03009    time: 1.2297  last_time: 1.2339  data_time: 0.0461  last_data_time: 0.0487   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:13:52 d2.utils.events]: \u001b[0m eta: 1:29:30  iter: 1619  total_loss: 0.328  loss_cls: 0.107  loss_box_reg: 0.1136  loss_rpn_cls: 0.04335  loss_rpn_loc: 0.06237    time: 1.2297  last_time: 1.1619  data_time: 0.0474  last_data_time: 0.0483   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:14:20 d2.utils.events]: \u001b[0m eta: 1:29:09  iter: 1639  total_loss: 0.2821  loss_cls: 0.1051  loss_box_reg: 0.1077  loss_rpn_cls: 0.03004  loss_rpn_loc: 0.03029    time: 1.2298  last_time: 1.2657  data_time: 0.0475  last_data_time: 0.0481   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:14:48 d2.utils.events]: \u001b[0m eta: 1:28:46  iter: 1659  total_loss: 0.2808  loss_cls: 0.1006  loss_box_reg: 0.1007  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.04263    time: 1.2298  last_time: 1.2311  data_time: 0.0492  last_data_time: 0.0474   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:15:16 d2.utils.events]: \u001b[0m eta: 1:28:22  iter: 1679  total_loss: 0.2913  loss_cls: 0.1042  loss_box_reg: 0.1108  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.04557    time: 1.2299  last_time: 1.2887  data_time: 0.0513  last_data_time: 0.0442   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:15:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:15:46 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:15:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:15:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:15:46 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:15:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:15:46 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:15:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0012 s/iter. Inference: 0.0551 s/iter. Eval: 0.0004 s/iter. Total: 0.0568 s/iter. ETA=0:02:53\n",
      "\u001b[32m[03/06 15:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 126/3060. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:02:10\n",
      "\u001b[32m[03/06 15:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 243/3060. Dataloading: 0.0013 s/iter. Inference: 0.0420 s/iter. Eval: 0.0003 s/iter. Total: 0.0437 s/iter. ETA=0:02:02\n",
      "\u001b[32m[03/06 15:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 359/3060. Dataloading: 0.0013 s/iter. Inference: 0.0420 s/iter. Eval: 0.0003 s/iter. Total: 0.0436 s/iter. ETA=0:01:57\n",
      "\u001b[32m[03/06 15:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 475/3060. Dataloading: 0.0013 s/iter. Inference: 0.0419 s/iter. Eval: 0.0003 s/iter. Total: 0.0435 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/06 15:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 591/3060. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0003 s/iter. Total: 0.0435 s/iter. ETA=0:01:47\n",
      "\u001b[32m[03/06 15:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 700/3060. Dataloading: 0.0013 s/iter. Inference: 0.0422 s/iter. Eval: 0.0003 s/iter. Total: 0.0439 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 15:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 819/3060. Dataloading: 0.0013 s/iter. Inference: 0.0420 s/iter. Eval: 0.0003 s/iter. Total: 0.0436 s/iter. ETA=0:01:37\n",
      "\u001b[32m[03/06 15:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 952/3060. Dataloading: 0.0013 s/iter. Inference: 0.0411 s/iter. Eval: 0.0003 s/iter. Total: 0.0428 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 15:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 1082/3060. Dataloading: 0.0013 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 15:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 1210/3060. Dataloading: 0.0013 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 15:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 1344/3060. Dataloading: 0.0013 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:11\n",
      "\u001b[32m[03/06 15:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 1465/3060. Dataloading: 0.0013 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/06 15:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 1576/3060. Dataloading: 0.0013 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 15:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 1686/3060. Dataloading: 0.0013 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:57\n",
      "\u001b[32m[03/06 15:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 1807/3060. Dataloading: 0.0013 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/06 15:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 1920/3060. Dataloading: 0.0013 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/06 15:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 2043/3060. Dataloading: 0.0013 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:42\n",
      "\u001b[32m[03/06 15:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 2157/3060. Dataloading: 0.0013 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 15:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 2263/3060. Dataloading: 0.0013 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 15:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 2381/3060. Dataloading: 0.0013 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 15:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 2495/3060. Dataloading: 0.0013 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 15:17:38 d2.evaluation.evaluator]: \u001b[0mInference done 2612/3060. Dataloading: 0.0013 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/06 15:17:43 d2.evaluation.evaluator]: \u001b[0mInference done 2720/3060. Dataloading: 0.0013 s/iter. Inference: 0.0410 s/iter. Eval: 0.0003 s/iter. Total: 0.0427 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/06 15:17:48 d2.evaluation.evaluator]: \u001b[0mInference done 2838/3060. Dataloading: 0.0013 s/iter. Inference: 0.0410 s/iter. Eval: 0.0003 s/iter. Total: 0.0427 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 15:17:53 d2.evaluation.evaluator]: \u001b[0mInference done 2949/3060. Dataloading: 0.0013 s/iter. Inference: 0.0411 s/iter. Eval: 0.0003 s/iter. Total: 0.0428 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 15:17:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:10.578396 (0.042743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:17:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:05 (0.041043 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:17:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:17:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:17:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.98s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      "\u001b[32m[03/06 15:18:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 9.013 | 17.605 | 7.818  | 0.081 | 3.507 | 11.838 |\n",
      "\u001b[32m[03/06 15:18:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 8.865 | bus        | 0.005  |\n",
      "| car        | 34.252 | construction equipment | 1.938 | emergency  | 28.153 |\n",
      "| motorbike  | 4.345  | personal mobility      | 1.107 | quad bike  | 2.451  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:18:02 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:18:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:18:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:18:02 d2.evaluation.testing]: \u001b[0mcopypaste: 9.0128,17.6051,7.8180,0.0810,3.5070,11.8379\n",
      "\u001b[32m[03/06 15:18:02 d2.utils.events]: \u001b[0m eta: 1:27:59  iter: 1699  total_loss: 0.2678  loss_cls: 0.09972  loss_box_reg: 0.104  loss_rpn_cls: 0.0269  loss_rpn_loc: 0.0425    time: 1.2302  last_time: 1.2332  data_time: 0.0563  last_data_time: 0.0442   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:18:31 d2.utils.events]: \u001b[0m eta: 1:27:36  iter: 1719  total_loss: 0.3032  loss_cls: 0.1055  loss_box_reg: 0.1115  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.04735    time: 1.2304  last_time: 1.2406  data_time: 0.0545  last_data_time: 0.0655   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:19:00 d2.utils.events]: \u001b[0m eta: 1:27:13  iter: 1739  total_loss: 0.2963  loss_cls: 0.1006  loss_box_reg: 0.1096  loss_rpn_cls: 0.03686  loss_rpn_loc: 0.0382    time: 1.2306  last_time: 1.2565  data_time: 0.0530  last_data_time: 0.0595   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:19:30 d2.utils.events]: \u001b[0m eta: 1:26:50  iter: 1759  total_loss: 0.2783  loss_cls: 0.0943  loss_box_reg: 0.1038  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.04057    time: 1.2309  last_time: 1.2185  data_time: 0.0577  last_data_time: 0.0909   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:19:58 d2.utils.events]: \u001b[0m eta: 1:26:25  iter: 1779  total_loss: 0.2953  loss_cls: 0.1033  loss_box_reg: 0.1085  loss_rpn_cls: 0.03188  loss_rpn_loc: 0.03933    time: 1.2311  last_time: 1.2185  data_time: 0.0557  last_data_time: 0.0399   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:20:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:20:27 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:20:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:20:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:20:27 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:20:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:20:27 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:20:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0010 s/iter. Inference: 0.0419 s/iter. Eval: 0.0002 s/iter. Total: 0.0432 s/iter. ETA=0:02:11\n",
      "\u001b[32m[03/06 15:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 127/3060. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0003 s/iter. Total: 0.0434 s/iter. ETA=0:02:07\n",
      "\u001b[32m[03/06 15:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 248/3060. Dataloading: 0.0013 s/iter. Inference: 0.0408 s/iter. Eval: 0.0003 s/iter. Total: 0.0425 s/iter. ETA=0:01:59\n",
      "\u001b[32m[03/06 15:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 374/3060. Dataloading: 0.0013 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:51\n",
      "\u001b[32m[03/06 15:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 486/3060. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:01:49\n",
      "\u001b[32m[03/06 15:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 609/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/06 15:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 729/3060. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:01:38\n",
      "\u001b[32m[03/06 15:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 854/3060. Dataloading: 0.0014 s/iter. Inference: 0.0401 s/iter. Eval: 0.0003 s/iter. Total: 0.0418 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/06 15:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 976/3060. Dataloading: 0.0014 s/iter. Inference: 0.0400 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:01:26\n",
      "\u001b[32m[03/06 15:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 1081/3060. Dataloading: 0.0014 s/iter. Inference: 0.0406 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 15:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 1195/3060. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0425 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 15:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 1321/3060. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0003 s/iter. Total: 0.0422 s/iter. ETA=0:01:13\n",
      "\u001b[32m[03/06 15:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 1438/3060. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:01:08\n",
      "\u001b[32m[03/06 15:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 1549/3060. Dataloading: 0.0014 s/iter. Inference: 0.0408 s/iter. Eval: 0.0003 s/iter. Total: 0.0425 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/06 15:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 1667/3060. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0425 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 15:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 1792/3060. Dataloading: 0.0014 s/iter. Inference: 0.0406 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:00:53\n",
      "\u001b[32m[03/06 15:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 1907/3060. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0424 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/06 15:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 2026/3060. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0003 s/iter. Total: 0.0424 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 15:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 2149/3060. Dataloading: 0.0014 s/iter. Inference: 0.0406 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 15:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 2278/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:00:32\n",
      "\u001b[32m[03/06 15:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 2397/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:00:27\n",
      "\u001b[32m[03/06 15:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 2518/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/06 15:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 2635/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:00:17\n",
      "\u001b[32m[03/06 15:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 2756/3060. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:00:12\n",
      "\u001b[32m[03/06 15:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 2869/3060. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0003 s/iter. Total: 0.0422 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 15:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 2984/3060. Dataloading: 0.0014 s/iter. Inference: 0.0406 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 15:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:08.985594 (0.042221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:03 (0.040515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:22:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:22:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:22:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.93s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[03/06 15:22:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 9.755 | 18.920 | 8.593  | 0.080 | 3.555 | 12.812 |\n",
      "\u001b[32m[03/06 15:22:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP    | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 9.521 | bus        | 0.006  |\n",
      "| car        | 35.313 | construction equipment | 2.236 | emergency  | 30.358 |\n",
      "| motorbike  | 5.013  | personal mobility      | 1.528 | quad bike  | 3.821  |\n",
      "| truck      | 0.000  |                        |       |            |        |\n",
      "\u001b[32m[03/06 15:22:43 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:22:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:22:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:22:43 d2.evaluation.testing]: \u001b[0mcopypaste: 9.7552,18.9205,8.5931,0.0799,3.5548,12.8119\n",
      "\u001b[32m[03/06 15:22:43 d2.utils.events]: \u001b[0m eta: 1:26:02  iter: 1799  total_loss: 0.2998  loss_cls: 0.1044  loss_box_reg: 0.107  loss_rpn_cls: 0.03692  loss_rpn_loc: 0.04892    time: 1.2312  last_time: 1.3204  data_time: 0.0600  last_data_time: 0.1168   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:23:11 d2.utils.events]: \u001b[0m eta: 1:25:37  iter: 1819  total_loss: 0.2853  loss_cls: 0.09676  loss_box_reg: 0.1009  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.04679    time: 1.2311  last_time: 1.2307  data_time: 0.0498  last_data_time: 0.0489   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:23:39 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 1839  total_loss: 0.2618  loss_cls: 0.09455  loss_box_reg: 0.1001  loss_rpn_cls: 0.03077  loss_rpn_loc: 0.03659    time: 1.2311  last_time: 1.2189  data_time: 0.0526  last_data_time: 0.0383   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:24:07 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 1859  total_loss: 0.3184  loss_cls: 0.1063  loss_box_reg: 0.1085  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.05558    time: 1.2311  last_time: 1.2227  data_time: 0.0521  last_data_time: 0.0594   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:24:35 d2.utils.events]: \u001b[0m eta: 1:24:23  iter: 1879  total_loss: 0.2733  loss_cls: 0.0945  loss_box_reg: 0.1018  loss_rpn_cls: 0.03398  loss_rpn_loc: 0.04036    time: 1.2309  last_time: 1.2221  data_time: 0.0526  last_data_time: 0.0577   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:25:03 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:25:03 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:25:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:25:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:25:03 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:25:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:25:03 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:25:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0004 s/iter. Inference: 0.0356 s/iter. Eval: 0.0002 s/iter. Total: 0.0363 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/06 15:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 141/3060. Dataloading: 0.0011 s/iter. Inference: 0.0370 s/iter. Eval: 0.0002 s/iter. Total: 0.0385 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/06 15:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 269/3060. Dataloading: 0.0012 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 15:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 395/3060. Dataloading: 0.0012 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:01:44\n",
      "\u001b[32m[03/06 15:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 524/3060. Dataloading: 0.0013 s/iter. Inference: 0.0375 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/06 15:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 650/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/06 15:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 779/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 15:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 907/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/06 15:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 1030/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/06 15:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 1154/3060. Dataloading: 0.0013 s/iter. Inference: 0.0379 s/iter. Eval: 0.0002 s/iter. Total: 0.0395 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 15:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 1285/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/06 15:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 1415/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/06 15:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 1540/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/06 15:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 1667/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/06 15:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 1798/3060. Dataloading: 0.0013 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 15:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 1929/3060. Dataloading: 0.0013 s/iter. Inference: 0.0377 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/06 15:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 2058/3060. Dataloading: 0.0013 s/iter. Inference: 0.0377 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:39\n",
      "\u001b[32m[03/06 15:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 2188/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:34\n",
      "\u001b[32m[03/06 15:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 2319/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:29\n",
      "\u001b[32m[03/06 15:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 2445/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:24\n",
      "\u001b[32m[03/06 15:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 2573/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:19\n",
      "\u001b[32m[03/06 15:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 2705/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 15:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 2834/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 15:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 2957/3060. Dataloading: 0.0013 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 15:27:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:59.819177 (0.039221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:27:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:54 (0.037627 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:27:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:27:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:27:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[03/06 15:27:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 10.314 | 19.804 | 9.166  | 0.095 | 3.621 | 13.639 |\n",
      "\u001b[32m[03/06 15:27:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:-------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 10.120 | bus        | 0.078  |\n",
      "| car        | 35.620 | construction equipment | 2.361  | emergency  | 32.289 |\n",
      "| motorbike  | 5.705  | personal mobility      | 2.645  | quad bike  | 4.007  |\n",
      "| truck      | 0.000  |                        |        |            |        |\n",
      "\u001b[32m[03/06 15:27:09 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:27:09 d2.evaluation.testing]: \u001b[0mcopypaste: 10.3140,19.8042,9.1660,0.0952,3.6207,13.6385\n",
      "\u001b[32m[03/06 15:27:09 d2.utils.events]: \u001b[0m eta: 1:23:58  iter: 1899  total_loss: 0.2699  loss_cls: 0.09338  loss_box_reg: 0.09752  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.04322    time: 1.2309  last_time: 1.2162  data_time: 0.0507  last_data_time: 0.0527   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:27:38 d2.utils.events]: \u001b[0m eta: 1:23:35  iter: 1919  total_loss: 0.2537  loss_cls: 0.09626  loss_box_reg: 0.09973  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.04006    time: 1.2310  last_time: 1.2314  data_time: 0.0559  last_data_time: 0.0559   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:28:06 d2.utils.events]: \u001b[0m eta: 1:23:11  iter: 1939  total_loss: 0.2909  loss_cls: 0.09721  loss_box_reg: 0.109  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.04644    time: 1.2310  last_time: 1.2200  data_time: 0.0518  last_data_time: 0.0380   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:28:34 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 1959  total_loss: 0.2703  loss_cls: 0.09543  loss_box_reg: 0.1038  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.04051    time: 1.2310  last_time: 1.2392  data_time: 0.0544  last_data_time: 0.0548   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:29:02 d2.utils.events]: \u001b[0m eta: 1:22:22  iter: 1979  total_loss: 0.2781  loss_cls: 0.09743  loss_box_reg: 0.103  loss_rpn_cls: 0.02923  loss_rpn_loc: 0.04707    time: 1.2310  last_time: 1.2247  data_time: 0.0512  last_data_time: 0.0443   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:29:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:29:31 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:29:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:29:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:29:31 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:29:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:29:31 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:29:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0005 s/iter. Inference: 0.0391 s/iter. Eval: 0.0003 s/iter. Total: 0.0398 s/iter. ETA=0:02:01\n",
      "\u001b[32m[03/06 15:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 139/3060. Dataloading: 0.0012 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:01:54\n",
      "\u001b[32m[03/06 15:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 267/3060. Dataloading: 0.0012 s/iter. Inference: 0.0377 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:01:49\n",
      "\u001b[32m[03/06 15:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 394/3060. Dataloading: 0.0012 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:01:44\n",
      "\u001b[32m[03/06 15:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 524/3060. Dataloading: 0.0012 s/iter. Inference: 0.0376 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/06 15:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 655/3060. Dataloading: 0.0012 s/iter. Inference: 0.0375 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:01:33\n",
      "\u001b[32m[03/06 15:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 784/3060. Dataloading: 0.0012 s/iter. Inference: 0.0375 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:01:28\n",
      "\u001b[32m[03/06 15:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 917/3060. Dataloading: 0.0012 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 15:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 1044/3060. Dataloading: 0.0012 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0389 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/06 15:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 1178/3060. Dataloading: 0.0012 s/iter. Inference: 0.0372 s/iter. Eval: 0.0002 s/iter. Total: 0.0387 s/iter. ETA=0:01:12\n",
      "\u001b[32m[03/06 15:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 1307/3060. Dataloading: 0.0012 s/iter. Inference: 0.0372 s/iter. Eval: 0.0002 s/iter. Total: 0.0387 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/06 15:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 1435/3060. Dataloading: 0.0012 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:01:03\n",
      "\u001b[32m[03/06 15:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 1562/3060. Dataloading: 0.0012 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0389 s/iter. ETA=0:00:58\n",
      "\u001b[32m[03/06 15:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 1692/3060. Dataloading: 0.0013 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:00:53\n",
      "\u001b[32m[03/06 15:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 1822/3060. Dataloading: 0.0013 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0388 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/06 15:30:47 d2.evaluation.evaluator]: \u001b[0mInference done 1948/3060. Dataloading: 0.0013 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0389 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 15:30:52 d2.evaluation.evaluator]: \u001b[0mInference done 2075/3060. Dataloading: 0.0013 s/iter. Inference: 0.0373 s/iter. Eval: 0.0002 s/iter. Total: 0.0389 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 15:30:57 d2.evaluation.evaluator]: \u001b[0mInference done 2200/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 15:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 2326/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 15:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 2455/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:23\n",
      "\u001b[32m[03/06 15:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 2583/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:18\n",
      "\u001b[32m[03/06 15:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 2713/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 15:31:22 d2.evaluation.evaluator]: \u001b[0mInference done 2840/3060. Dataloading: 0.0013 s/iter. Inference: 0.0374 s/iter. Eval: 0.0002 s/iter. Total: 0.0390 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 15:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 2963/3060. Dataloading: 0.0013 s/iter. Inference: 0.0375 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 15:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:59.448697 (0.039099 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:54 (0.037504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:31:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:31:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:31:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
      "\u001b[32m[03/06 15:31:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 10.798 | 21.031 | 9.313  | 0.152 | 3.799 | 14.405 |\n",
      "\u001b[32m[03/06 15:31:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:-------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 10.568 | bus        | 0.181  |\n",
      "| car        | 36.468 | construction equipment | 2.621  | emergency  | 32.285 |\n",
      "| motorbike  | 5.942  | personal mobility      | 4.753  | quad bike  | 4.364  |\n",
      "| truck      | 0.000  |                        |        |            |        |\n",
      "\u001b[32m[03/06 15:31:36 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:31:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:31:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:31:36 d2.evaluation.testing]: \u001b[0mcopypaste: 10.7981,21.0308,9.3134,0.1516,3.7995,14.4052\n",
      "\u001b[32m[03/06 15:31:37 d2.utils.events]: \u001b[0m eta: 1:21:58  iter: 1999  total_loss: 0.2712  loss_cls: 0.09948  loss_box_reg: 0.1015  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.03285    time: 1.2311  last_time: 1.2772  data_time: 0.0520  last_data_time: 0.0545   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:32:05 d2.utils.events]: \u001b[0m eta: 1:21:34  iter: 2019  total_loss: 0.2647  loss_cls: 0.09397  loss_box_reg: 0.09916  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.03661    time: 1.2312  last_time: 1.2370  data_time: 0.0558  last_data_time: 0.0675   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:32:34 d2.utils.events]: \u001b[0m eta: 1:21:10  iter: 2039  total_loss: 0.3007  loss_cls: 0.1033  loss_box_reg: 0.1065  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.03971    time: 1.2314  last_time: 1.2428  data_time: 0.0534  last_data_time: 0.0583   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:33:02 d2.utils.events]: \u001b[0m eta: 1:20:47  iter: 2059  total_loss: 0.2744  loss_cls: 0.0959  loss_box_reg: 0.09898  loss_rpn_cls: 0.03116  loss_rpn_loc: 0.04357    time: 1.2315  last_time: 1.2417  data_time: 0.0514  last_data_time: 0.0446   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:33:31 d2.utils.events]: \u001b[0m eta: 1:20:25  iter: 2079  total_loss: 0.2751  loss_cls: 0.09713  loss_box_reg: 0.1053  loss_rpn_cls: 0.03072  loss_rpn_loc: 0.05049    time: 1.2317  last_time: 1.2650  data_time: 0.0531  last_data_time: 0.0459   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:34:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:34:00 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:34:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:34:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:34:00 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:34:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:34:00 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:34:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0012 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:05\n",
      "\u001b[32m[03/06 15:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 135/3060. Dataloading: 0.0012 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:58\n",
      "\u001b[32m[03/06 15:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 254/3060. Dataloading: 0.0012 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:55\n",
      "\u001b[32m[03/06 15:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 378/3060. Dataloading: 0.0012 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/06 15:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 501/3060. Dataloading: 0.0013 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:44\n",
      "\u001b[32m[03/06 15:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 620/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 15:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 739/3060. Dataloading: 0.0013 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 15:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 865/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 15:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 985/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:25\n",
      "\u001b[32m[03/06 15:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 1106/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:20\n",
      "\u001b[32m[03/06 15:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 1226/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:01:15\n",
      "\u001b[32m[03/06 15:34:57 d2.evaluation.evaluator]: \u001b[0mInference done 1346/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0414 s/iter. ETA=0:01:10\n",
      "\u001b[32m[03/06 15:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 1466/3060. Dataloading: 0.0013 s/iter. Inference: 0.0398 s/iter. Eval: 0.0003 s/iter. Total: 0.0414 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/06 15:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 1592/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/06 15:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 1713/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:55\n",
      "\u001b[32m[03/06 15:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 1838/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:50\n",
      "\u001b[32m[03/06 15:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 1956/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/06 15:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 2078/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/06 15:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 2201/3060. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:35\n",
      "\u001b[32m[03/06 15:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 2320/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/06 15:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 2440/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0414 s/iter. ETA=0:00:25\n",
      "\u001b[32m[03/06 15:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 2563/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/06 15:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 2684/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:15\n",
      "\u001b[32m[03/06 15:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 2805/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:10\n",
      "\u001b[32m[03/06 15:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 2924/3060. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:05\n",
      "\u001b[32m[03/06 15:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 3041/3060. Dataloading: 0.0013 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/06 15:36:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:06.674881 (0.041465 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:36:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:01 (0.039796 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:36:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:36:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:36:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
      "\u001b[32m[03/06 15:36:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.474 | 22.081 | 9.912  | 0.233 | 3.951 | 15.283 |\n",
      "\u001b[32m[03/06 15:36:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:-------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 11.150 | bus        | 0.318  |\n",
      "| car        | 37.118 | construction equipment | 3.073  | emergency  | 33.574 |\n",
      "| motorbike  | 6.443  | personal mobility      | 5.856  | quad bike  | 5.732  |\n",
      "| truck      | 0.000  |                        |        |            |        |\n",
      "\u001b[32m[03/06 15:36:13 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:36:13 d2.evaluation.testing]: \u001b[0mcopypaste: 11.4737,22.0808,9.9123,0.2330,3.9505,15.2827\n",
      "\u001b[32m[03/06 15:36:13 d2.utils.events]: \u001b[0m eta: 1:20:02  iter: 2099  total_loss: 0.2731  loss_cls: 0.09722  loss_box_reg: 0.1039  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.04791    time: 1.2319  last_time: 1.2444  data_time: 0.0562  last_data_time: 0.0573   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:36:42 d2.utils.events]: \u001b[0m eta: 1:19:39  iter: 2119  total_loss: 0.2774  loss_cls: 0.09381  loss_box_reg: 0.1044  loss_rpn_cls: 0.03005  loss_rpn_loc: 0.04262    time: 1.2322  last_time: 1.2738  data_time: 0.0548  last_data_time: 0.0586   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:37:12 d2.utils.events]: \u001b[0m eta: 1:19:16  iter: 2139  total_loss: 0.2581  loss_cls: 0.08845  loss_box_reg: 0.09824  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.0376    time: 1.2325  last_time: 1.2724  data_time: 0.0566  last_data_time: 0.0770   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:37:41 d2.utils.events]: \u001b[0m eta: 1:18:54  iter: 2159  total_loss: 0.2693  loss_cls: 0.09522  loss_box_reg: 0.1042  loss_rpn_cls: 0.03141  loss_rpn_loc: 0.03586    time: 1.2329  last_time: 1.2735  data_time: 0.0588  last_data_time: 0.0529   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:38:11 d2.utils.events]: \u001b[0m eta: 1:18:31  iter: 2179  total_loss: 0.2527  loss_cls: 0.09291  loss_box_reg: 0.09625  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.03672    time: 1.2332  last_time: 1.2552  data_time: 0.0552  last_data_time: 0.0553   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:38:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:38:41 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:38:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:38:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:38:41 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:38:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:38:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:38:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0005 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:02:22\n",
      "\u001b[32m[03/06 15:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 111/3060. Dataloading: 0.0014 s/iter. Inference: 0.0483 s/iter. Eval: 0.0003 s/iter. Total: 0.0501 s/iter. ETA=0:02:27\n",
      "\u001b[32m[03/06 15:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 208/3060. Dataloading: 0.0015 s/iter. Inference: 0.0491 s/iter. Eval: 0.0003 s/iter. Total: 0.0510 s/iter. ETA=0:02:25\n",
      "\u001b[32m[03/06 15:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 305/3060. Dataloading: 0.0015 s/iter. Inference: 0.0493 s/iter. Eval: 0.0003 s/iter. Total: 0.0512 s/iter. ETA=0:02:21\n",
      "\u001b[32m[03/06 15:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 404/3060. Dataloading: 0.0015 s/iter. Inference: 0.0492 s/iter. Eval: 0.0003 s/iter. Total: 0.0511 s/iter. ETA=0:02:15\n",
      "\u001b[32m[03/06 15:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 505/3060. Dataloading: 0.0015 s/iter. Inference: 0.0489 s/iter. Eval: 0.0003 s/iter. Total: 0.0508 s/iter. ETA=0:02:09\n",
      "\u001b[32m[03/06 15:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 608/3060. Dataloading: 0.0015 s/iter. Inference: 0.0486 s/iter. Eval: 0.0003 s/iter. Total: 0.0505 s/iter. ETA=0:02:03\n",
      "\u001b[32m[03/06 15:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 720/3060. Dataloading: 0.0015 s/iter. Inference: 0.0477 s/iter. Eval: 0.0003 s/iter. Total: 0.0496 s/iter. ETA=0:01:56\n",
      "\u001b[32m[03/06 15:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 831/3060. Dataloading: 0.0015 s/iter. Inference: 0.0472 s/iter. Eval: 0.0003 s/iter. Total: 0.0490 s/iter. ETA=0:01:49\n",
      "\u001b[32m[03/06 15:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 945/3060. Dataloading: 0.0015 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:01:42\n",
      "\u001b[32m[03/06 15:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 1058/3060. Dataloading: 0.0015 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:36\n",
      "\u001b[32m[03/06 15:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 1173/3060. Dataloading: 0.0015 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/06 15:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 1286/3060. Dataloading: 0.0015 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:23\n",
      "\u001b[32m[03/06 15:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 1396/3060. Dataloading: 0.0015 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/06 15:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 1510/3060. Dataloading: 0.0015 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:12\n",
      "\u001b[32m[03/06 15:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 1629/3060. Dataloading: 0.0015 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/06 15:40:03 d2.evaluation.evaluator]: \u001b[0mInference done 1744/3060. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/06 15:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 1864/3060. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:55\n",
      "\u001b[32m[03/06 15:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 1982/3060. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/06 15:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 2099/3060. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:00:43\n",
      "\u001b[32m[03/06 15:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 2211/3060. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 15:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 2320/3060. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 15:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 2435/3060. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 15:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 2548/3060. Dataloading: 0.0015 s/iter. Inference: 0.0437 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:00:23\n",
      "\u001b[32m[03/06 15:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 2653/3060. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:00:18\n",
      "\u001b[32m[03/06 15:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 2759/3060. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 15:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 2860/3060. Dataloading: 0.0015 s/iter. Inference: 0.0440 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/06 15:40:58 d2.evaluation.evaluator]: \u001b[0mInference done 2954/3060. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:04\n",
      "\u001b[32m[03/06 15:41:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:20.909874 (0.046124 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:41:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:15 (0.044247 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:41:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:41:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:41:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=5.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.58s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
      "\u001b[32m[03/06 15:41:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.879 | 22.934 | 10.196 | 0.383 | 4.086 | 15.685 |\n",
      "\u001b[32m[03/06 15:41:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:-------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 11.579 | bus        | 0.780  |\n",
      "| car        | 37.733 | construction equipment | 2.936  | emergency  | 35.271 |\n",
      "| motorbike  | 6.397  | personal mobility      | 6.178  | quad bike  | 6.040  |\n",
      "| truck      | 0.000  |                        |        |            |        |\n",
      "\u001b[32m[03/06 15:41:10 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:41:10 d2.evaluation.testing]: \u001b[0mcopypaste: 11.8794,22.9341,10.1964,0.3832,4.0859,15.6847\n",
      "\u001b[32m[03/06 15:41:10 d2.utils.events]: \u001b[0m eta: 1:18:09  iter: 2199  total_loss: 0.2577  loss_cls: 0.09568  loss_box_reg: 0.09935  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.02755    time: 1.2336  last_time: 1.2652  data_time: 0.0682  last_data_time: 0.0678   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:41:40 d2.utils.events]: \u001b[0m eta: 1:17:45  iter: 2219  total_loss: 0.2879  loss_cls: 0.08972  loss_box_reg: 0.09884  loss_rpn_cls: 0.03898  loss_rpn_loc: 0.06402    time: 1.2340  last_time: 1.2917  data_time: 0.0585  last_data_time: 0.0516   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:42:10 d2.utils.events]: \u001b[0m eta: 1:17:22  iter: 2239  total_loss: 0.2854  loss_cls: 0.09802  loss_box_reg: 0.09858  loss_rpn_cls: 0.03094  loss_rpn_loc: 0.05085    time: 1.2344  last_time: 1.3403  data_time: 0.0588  last_data_time: 0.0738   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:42:40 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 2259  total_loss: 0.2565  loss_cls: 0.08516  loss_box_reg: 0.09173  loss_rpn_cls: 0.03405  loss_rpn_loc: 0.04113    time: 1.2347  last_time: 1.2962  data_time: 0.0591  last_data_time: 0.0690   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:43:10 d2.utils.events]: \u001b[0m eta: 1:16:37  iter: 2279  total_loss: 0.2904  loss_cls: 0.09011  loss_box_reg: 0.09424  loss_rpn_cls: 0.03333  loss_rpn_loc: 0.05466    time: 1.2352  last_time: 1.3017  data_time: 0.0795  last_data_time: 0.0931   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/06 15:43:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/06 15:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 3060 images in COCO format from Vehicle detection.v9i.coco/valid/_annotations.coco.json\n",
      "\u001b[32m[03/06 15:43:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/06 15:43:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[03/06 15:43:41 d2.data.common]: \u001b[0mSerializing 3060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/06 15:43:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.80 MiB\n",
      "\u001b[32m[03/06 15:43:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[03/06 15:43:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 3060 batches\n",
      "\u001b[32m[03/06 15:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/3060. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0003 s/iter. Total: 0.0517 s/iter. ETA=0:02:37\n",
      "\u001b[32m[03/06 15:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 117/3060. Dataloading: 0.0015 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:02:19\n",
      "\u001b[32m[03/06 15:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 226/3060. Dataloading: 0.0015 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:12\n",
      "\u001b[32m[03/06 15:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 333/3060. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:07\n",
      "\u001b[32m[03/06 15:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 445/3060. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:02:01\n",
      "\u001b[32m[03/06 15:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 549/3060. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:01:57\n",
      "\u001b[32m[03/06 15:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 655/3060. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/06 15:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 760/3060. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/06 15:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 861/3060. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:01:44\n",
      "\u001b[32m[03/06 15:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 961/3060. Dataloading: 0.0016 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/06 15:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 1071/3060. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/06 15:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 1171/3060. Dataloading: 0.0016 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:30\n",
      "\u001b[32m[03/06 15:44:42 d2.evaluation.evaluator]: \u001b[0mInference done 1273/3060. Dataloading: 0.0016 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0478 s/iter. ETA=0:01:25\n",
      "\u001b[32m[03/06 15:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 1372/3060. Dataloading: 0.0017 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:01:21\n",
      "\u001b[32m[03/06 15:44:52 d2.evaluation.evaluator]: \u001b[0mInference done 1465/3060. Dataloading: 0.0017 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/06 15:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 1568/3060. Dataloading: 0.0017 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:01:12\n",
      "\u001b[32m[03/06 15:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 1672/3060. Dataloading: 0.0017 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/06 15:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 1770/3060. Dataloading: 0.0017 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:01:02\n",
      "\u001b[32m[03/06 15:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 1873/3060. Dataloading: 0.0017 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:57\n",
      "\u001b[32m[03/06 15:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 1973/3060. Dataloading: 0.0017 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:52\n",
      "\u001b[32m[03/06 15:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 2075/3060. Dataloading: 0.0017 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:47\n",
      "\u001b[32m[03/06 15:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 2179/3060. Dataloading: 0.0017 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:42\n",
      "\u001b[32m[03/06 15:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 2275/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/06 15:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 2381/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:33\n",
      "\u001b[32m[03/06 15:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 2484/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:28\n",
      "\u001b[32m[03/06 15:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 2588/3060. Dataloading: 0.0017 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/06 15:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 2692/3060. Dataloading: 0.0017 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:17\n",
      "\u001b[32m[03/06 15:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 2791/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:13\n",
      "\u001b[32m[03/06 15:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 2895/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:08\n",
      "\u001b[32m[03/06 15:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 2996/3060. Dataloading: 0.0017 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0488 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/06 15:46:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:29.133992 (0.048816 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:46:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:22 (0.046713 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/06 15:46:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/06 15:46:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 4_output/validation-set-evaluation/coco_instances_results.json\n",
      "\u001b[32m[03/06 15:46:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.44s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.98s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      "\u001b[32m[03/06 15:46:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 12.333 | 23.991 | 10.466 | 0.431 | 4.172 | 16.402 |\n",
      "\u001b[32m[03/06 15:46:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category               | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------------------|:-------|:-----------|:-------|\n",
      "| cars       | nan    | bike                   | 12.227 | bus        | 1.382  |\n",
      "| car        | 38.761 | construction equipment | 2.711  | emergency  | 36.185 |\n",
      "| motorbike  | 6.668  | personal mobility      | 6.345  | quad bike  | 6.713  |\n",
      "| truck      | 0.000  |                        |        |            |        |\n",
      "\u001b[32m[03/06 15:46:17 d2.engine.defaults]: \u001b[0mEvaluation results for vehicles_val in csv format:\n",
      "\u001b[32m[03/06 15:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/06 15:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/06 15:46:17 d2.evaluation.testing]: \u001b[0mcopypaste: 12.3326,23.9906,10.4661,0.4308,4.1717,16.4024\n",
      "\u001b[32m[03/06 15:46:17 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 2299  total_loss: 0.3078  loss_cls: 0.1011  loss_box_reg: 0.103  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.04608    time: 1.2355  last_time: 1.2505  data_time: 0.0631  last_data_time: 0.0601   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:46:49 d2.utils.events]: \u001b[0m eta: 1:15:51  iter: 2319  total_loss: 0.262  loss_cls: 0.09145  loss_box_reg: 0.09559  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.04697    time: 1.2363  last_time: 1.4131  data_time: 0.0648  last_data_time: 0.0603   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:47:21 d2.utils.events]: \u001b[0m eta: 1:15:32  iter: 2339  total_loss: 0.2472  loss_cls: 0.08805  loss_box_reg: 0.09125  loss_rpn_cls: 0.02569  loss_rpn_loc: 0.0421    time: 1.2371  last_time: 1.2538  data_time: 0.0671  last_data_time: 0.0502   lr: 0.00025  max_mem: 13695M\n",
      "\u001b[32m[03/06 15:47:53 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 2359  total_loss: 0.2496  loss_cls: 0.08662  loss_box_reg: 0.09496  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.03395    time: 1.2377  last_time: 1.2663  data_time: 0.0704  last_data_time: 0.0681   lr: 0.00025  max_mem: 13695M\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"vehicles_train\",)\n",
    "cfg.DATASETS.TEST= (\"vehicles_val\",)\n",
    "cfg.OUTPUT_DIR = (\"4_output\") # TODO: Исправить на автосмену\n",
    "cfg.OUTPUT_DIR_VALIDATION_SET_EVALUATION = os.path.join(\n",
    "        cfg.OUTPUT_DIR, \"validation-set-evaluation\")\n",
    "cfg.OUTPUT_DIR_TEST_SET_EVALUATION = os.path.join(\n",
    "        cfg.OUTPUT_DIR, \"test-set-evaluation\")\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 12\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 20  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 6000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 9  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(cfg.OUTPUT_DIR_VALIDATION_SET_EVALUATION, exist_ok=True)\n",
    "os.makedirs(cfg.OUTPUT_DIR_TEST_SET_EVALUATION, exist_ok=True)\n",
    "\n",
    "#setup_logger(output=os.path.join(cfg.OUTPUT_DIR, \"training-log.txt\"))\n",
    "\n",
    "mlflow_hook = MLflowHook(cfg)\n",
    "\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.register_hooks(hooks=[mlflow_hook])\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "#setup_logger(output=os.path.join(cfg.OUTPUT_DIR_TEST_SET_EVALUATION, \"evaluation-log.txt\"))\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "evaluator = COCOEvaluator(\"v\", output_dir=cfg.OUTPUT_DIR_TEST_SET_EVALUATION)\n",
    "test_set_loader = build_detection_test_loader(cfg, \"v\")\n",
    "\n",
    "evaluation_results = inference_on_dataset(predictor.model, test_set_loader, evaluator)\n",
    "#logging.info(\"Evaluation results on test set: %s\", evaluation_results)\n",
    "\n",
    "for k, v in evaluation_results[\"bbox\"].items():\n",
    "    mlflow.log_metric(f\"Test Set {k}\", v, step=0)\n",
    "\n",
    "mlflow.log_artifacts(cfg.OUTPUT_DIR_TEST_SET_EVALUATION, \"test-set-evaluation\")\n",
    "mlflow.log_text(str(evaluation_results), \"test-set-evaluation/coco-metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.65   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "dataset_name = 'vehicles_test'\n",
    "dataset_metadata = MetadataCatalog.get(dataset_name)\n",
    "\n",
    "\n",
    "input_images = [\n",
    "    \"Vehilce detection.v3i.coco/train/1ff7910c-16884491480894_jpeg.rf.70dbfcc5722372608719d20b68a71541.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/fe27f76c-electricScooter_114_jpg.rf.6dfaaaa049ee65ef79cb656a14d3a35f.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/f7ab2b5f-52_jpg.rf.93d3972b5242280d38f273f74a001319.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/d951a446-i_jpg.rf.e4682497eda25d2d639e83d1d655d4fc.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/b7fcd547-60d072afa40cf3d4e89a928913630124_jpeg.rf.a49d2a003e30c8b32865f3d43f4933bb.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/846cf55e-42_jpg.rf.ad0ad373bdc619d1e1771b549c72f4cb.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/4c9f0301-monowheel_12_jpg.rf.dbdfdfa6a003e1aea4ab9e69aa208def.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/4e42ee0c-_-_-_10_jpg.rf.d8cb4a8f3ecd5146efd79270376b954d.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/train/ant_sales-1030_png_jpg.rf.e6122844adc05593c86d492d2b818543.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/valid/image25_png_jpg.rf.8ad9ec59347c435970f2142ff7074cbe.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/valid/screenshot_17440_jpg.rf.0fa15167b99fcc4380da5e0433a63ed9.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/valid/screenshot_13131_jpg.rf.603f483cb49a9f7e300979b26f65e6e3.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/valid/screenshot_1341_jpg.rf.0e6e1343b17c6f262ac96e211636c427.jpg\",\n",
    "    \"Vehilce detection.v3i.coco/valid/image07_png_jpg.rf.4f472e89f7ba03ac51d8ed81c8c9e897.jpg\",\n",
    "]\n",
    "\n",
    "\n",
    "output_dir = cfg.OUTPUT_DIR_TEST_SET_EVALUATION\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for input_image_path in input_images:\n",
    "    im = Image.open(input_image_path)\n",
    "    im = np.array(im)\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    vis_output = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "\n",
    "    output_image = vis_output.get_image()[:, :, ::-1]\n",
    "\n",
    "\n",
    "    output_image_path = os.path.join(output_dir, os.path.basename(input_image_path))\n",
    "    \n",
    " \n",
    "    Image.fromarray(output_image).save(output_image_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! jupyter notebook stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
